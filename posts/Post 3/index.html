<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Emma Rasmussen">
<meta name="dcterms.date" content="2022-05-22">
<meta name="description" content="Machine Learning to Interpret Cardiotocograms (CTGs)">

<title>Emma Rasmussen DACSS Blog - Machine Learning Final Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Emma Rasmussen DACSS Blog</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/emmarasmussen"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Machine Learning Final Project</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Machine Learning to Interpret Cardiotocograms (CTGs)
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Emma Rasmussen </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 22, 2022</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#exploratory-data-analysis-and-data-preprocessing" id="toc-exploratory-data-analysis-and-data-preprocessing" class="nav-link" data-scroll-target="#exploratory-data-analysis-and-data-preprocessing">Exploratory Data Analysis and Data Preprocessing</a>
  <ul class="collapse">
  <li><a href="#creating-dummy-variables-from-histogram-tendency-variable" id="toc-creating-dummy-variables-from-histogram-tendency-variable" class="nav-link" data-scroll-target="#creating-dummy-variables-from-histogram-tendency-variable">Creating Dummy Variables from Histogram Tendency Variable</a></li>
  <li><a href="#creating-a-binary-outcome-variables" id="toc-creating-a-binary-outcome-variables" class="nav-link" data-scroll-target="#creating-a-binary-outcome-variables">Creating a Binary Outcome Variables</a></li>
  <li><a href="#creating-ordered-factors-for-3-class-outcome" id="toc-creating-ordered-factors-for-3-class-outcome" class="nav-link" data-scroll-target="#creating-ordered-factors-for-3-class-outcome">Creating Ordered Factors for 3 Class Outcome:</a></li>
  <li><a href="#splitting-the-data" id="toc-splitting-the-data" class="nav-link" data-scroll-target="#splitting-the-data">Splitting the Data</a></li>
  </ul></li>
  <li><a href="#evaluation-metric" id="toc-evaluation-metric" class="nav-link" data-scroll-target="#evaluation-metric">Evaluation Metric</a></li>
  <li><a href="#fit-models" id="toc-fit-models" class="nav-link" data-scroll-target="#fit-models">Fit Models</a>
  <ul class="collapse">
  <li><a href="#python-set-up" id="toc-python-set-up" class="nav-link" data-scroll-target="#python-set-up">Python Set-Up</a></li>
  <li><a href="#defining-a-function-to-remove-outliers-based-on-z-score" id="toc-defining-a-function-to-remove-outliers-based-on-z-score" class="nav-link" data-scroll-target="#defining-a-function-to-remove-outliers-based-on-z-score">Defining a Function to Remove Outliers Based on Z-score</a></li>
  <li><a href="#penalized-logistic-regression" id="toc-penalized-logistic-regression" class="nav-link" data-scroll-target="#penalized-logistic-regression">Penalized Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#testing-l1-and-l2-penalty" id="toc-testing-l1-and-l2-penalty" class="nav-link" data-scroll-target="#testing-l1-and-l2-penalty">Testing l1 and l2 Penalty</a></li>
  <li><a href="#defining-a-function-to-return-macro-f1-scores-and-by-class-f1-scores" id="toc-defining-a-function-to-return-macro-f1-scores-and-by-class-f1-scores" class="nav-link" data-scroll-target="#defining-a-function-to-return-macro-f1-scores-and-by-class-f1-scores">Defining a Function to Return Macro f1 Scores and By-Class F1 Scores</a></li>
  </ul></li>
  <li><a href="#elastic-net-regularization" id="toc-elastic-net-regularization" class="nav-link" data-scroll-target="#elastic-net-regularization">Elastic Net Regularization</a></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting">Boosting</a></li>
  <li><a href="#support-vector-machines-svm" id="toc-support-vector-machines-svm" class="nav-link" data-scroll-target="#support-vector-machines-svm">Support Vector Machines (SVM)</a></li>
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a></li>
  <li><a href="#final-model-evaluation" id="toc-final-model-evaluation" class="nav-link" data-scroll-target="#final-model-evaluation">Final Model Evaluation</a>
  <ul class="collapse">
  <li><a href="#test-set-pre-processing" id="toc-test-set-pre-processing" class="nav-link" data-scroll-target="#test-set-pre-processing">Test set pre-processing</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a></li>
  <li><a href="#boosting-1" id="toc-boosting-1" class="nav-link" data-scroll-target="#boosting-1">Boosting</a></li>
  <li><a href="#support-vector-machines" id="toc-support-vector-machines" class="nav-link" data-scroll-target="#support-vector-machines">Support Vector Machines</a></li>
  <li><a href="#k-nearest-neighbors" id="toc-k-nearest-neighbors" class="nav-link" data-scroll-target="#k-nearest-neighbors">K-Nearest Neighbors</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#compare-models" id="toc-compare-models" class="nav-link" data-scroll-target="#compare-models">Compare Models</a></li>
  <li><a href="#ethical-implications" id="toc-ethical-implications" class="nav-link" data-scroll-target="#ethical-implications">Ethical Implications</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> <span class="cn">TRUE</span>, <span class="at">warning=</span><span class="cn">FALSE</span>, <span class="at">message=</span><span class="cn">FALSE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VIM)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lubridate)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MLmetrics)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastDummies)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">virtualenv_create</span>(<span class="st">"MLFinal"</span>) <span class="co">#create virtual environment... per reticulate cheat sheet</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>virtualenv: MLFinal</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"pandas"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"numpy"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"xgboost"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">conda_install</span>(<span class="st">"MLFinal"</span>, <span class="st">"scikit-learn"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"MLFinal"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>knit_engines<span class="sc">$</span><span class="fu">set</span>(<span class="at">python =</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span>eng_python) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="motivation" class="level1">
<h1>Motivation</h1>
<p>Cardiotocograms (CTGs) are used during labor and late stage pregnancy to monitor fetal and maternal health. CTGs (also called electronic fetal monitoring, EFM) use ultrasound transducers to record fetal heart rate and Braxton Hicks contractions. CTGs can indicate if a fetus is at risk for hypoxia (lack of oxygen). Variables like histogram_mode (etc) are referring to fetal heart rate histograms. An example CTG is pictured below:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="CTG_Output.jpeg" class="img-fluid" width="438"></p>
</div>
</div>
<p>Image Source: (Cardiotocography 2023)</p>
<p>On the CTG, (A) shows fetal heartbeat, (B) shows fetal movement felt by the mother, (C) shows recorded fetal movement, and (D) shows uterine contractions.</p>
<p>A fetus at risk for hypoxia is considered “pathological” and in need of immediate attention. Suspect cases may have one characteristic that strays from normal but are not at an immediate risk.</p>
<p>In the fetal health data set used in this analysis, the classification into categories (normal (1), suspect (2), and pathological (3)) was done by “expert obstetricians” interpreting the CTG results (Ayres de Campos et al.&nbsp;2000).</p>
<p>The motivation behind creating a machine learning algorithm to interpret these CTGs is to:</p>
<ul>
<li><p>Aid human interpretation of CTGs, make results more accessible to untrained individuals</p></li>
<li><p>Speed up human interpretation</p></li>
<li><p>Potentially help reduce biases in the medical system (for instance, discounting an individuals concerns based on race or ethnicity). An algorithm based on the variables in our dataset should not hold these biases.</p></li>
</ul>
<p>This document is created with R Markdown and uses R’s ‘reticulate’ package to integrate Python code. Most visualizations and data cleaning is done in R, while the machine learning algorithms are run in Python.</p>
</section>
<section id="exploratory-data-analysis-and-data-preprocessing" class="level1">
<h1>Exploratory Data Analysis and Data Preprocessing</h1>
<p>Read in the Data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"fetal_health.csv"</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Look at size of data frame and summary statistics:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(fet_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2126   22</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fet_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> baseline.value  accelerations      fetal_movement     uterine_contractions
 Min.   :106.0   Min.   :0.000000   Min.   :0.000000   Min.   :0.000000    
 1st Qu.:126.0   1st Qu.:0.000000   1st Qu.:0.000000   1st Qu.:0.002000    
 Median :133.0   Median :0.002000   Median :0.000000   Median :0.004000    
 Mean   :133.3   Mean   :0.003178   Mean   :0.009481   Mean   :0.004366    
 3rd Qu.:140.0   3rd Qu.:0.006000   3rd Qu.:0.003000   3rd Qu.:0.007000    
 Max.   :160.0   Max.   :0.019000   Max.   :0.481000   Max.   :0.015000    
 light_decelerations severe_decelerations prolongued_decelerations
 Min.   :0.000000    Min.   :0.000e+00    Min.   :0.0000000       
 1st Qu.:0.000000    1st Qu.:0.000e+00    1st Qu.:0.0000000       
 Median :0.000000    Median :0.000e+00    Median :0.0000000       
 Mean   :0.001889    Mean   :3.293e-06    Mean   :0.0001585       
 3rd Qu.:0.003000    3rd Qu.:0.000e+00    3rd Qu.:0.0000000       
 Max.   :0.015000    Max.   :1.000e-03    Max.   :0.0050000       
 abnormal_short_term_variability mean_value_of_short_term_variability
 Min.   :12.00                   Min.   :0.200                       
 1st Qu.:32.00                   1st Qu.:0.700                       
 Median :49.00                   Median :1.200                       
 Mean   :46.99                   Mean   :1.333                       
 3rd Qu.:61.00                   3rd Qu.:1.700                       
 Max.   :87.00                   Max.   :7.000                       
 percentage_of_time_with_abnormal_long_term_variability
 Min.   : 0.000                                        
 1st Qu.: 0.000                                        
 Median : 0.000                                        
 Mean   : 9.847                                        
 3rd Qu.:11.000                                        
 Max.   :91.000                                        
 mean_value_of_long_term_variability histogram_width  histogram_min   
 Min.   : 0.000                      Min.   :  3.00   Min.   : 50.00  
 1st Qu.: 4.600                      1st Qu.: 37.00   1st Qu.: 67.00  
 Median : 7.400                      Median : 67.50   Median : 93.00  
 Mean   : 8.188                      Mean   : 70.45   Mean   : 93.58  
 3rd Qu.:10.800                      3rd Qu.:100.00   3rd Qu.:120.00  
 Max.   :50.700                      Max.   :180.00   Max.   :159.00  
 histogram_max histogram_number_of_peaks histogram_number_of_zeroes
 Min.   :122   Min.   : 0.000            Min.   : 0.0000           
 1st Qu.:152   1st Qu.: 2.000            1st Qu.: 0.0000           
 Median :162   Median : 3.000            Median : 0.0000           
 Mean   :164   Mean   : 4.068            Mean   : 0.3236           
 3rd Qu.:174   3rd Qu.: 6.000            3rd Qu.: 0.0000           
 Max.   :238   Max.   :18.000            Max.   :10.0000           
 histogram_mode  histogram_mean  histogram_median histogram_variance
 Min.   : 60.0   Min.   : 73.0   Min.   : 77.0    Min.   :  0.00    
 1st Qu.:129.0   1st Qu.:125.0   1st Qu.:129.0    1st Qu.:  2.00    
 Median :139.0   Median :136.0   Median :139.0    Median :  7.00    
 Mean   :137.5   Mean   :134.6   Mean   :138.1    Mean   : 18.81    
 3rd Qu.:148.0   3rd Qu.:145.0   3rd Qu.:148.0    3rd Qu.: 24.00    
 Max.   :187.0   Max.   :182.0   Max.   :186.0    Max.   :269.00    
 histogram_tendency fetal_health
 Min.   :-1.0000    1:1655      
 1st Qu.: 0.0000    2: 295      
 Median : 0.0000    3: 176      
 Mean   : 0.3203                
 3rd Qu.: 1.0000                
 Max.   : 1.0000                </code></pre>
</div>
</div>
<p>The data has 2126 observations and 22 variables.</p>
<p>Check for missing values:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(fet_df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                        baseline.value 
                                                     0 
                                         accelerations 
                                                     0 
                                        fetal_movement 
                                                     0 
                                  uterine_contractions 
                                                     0 
                                   light_decelerations 
                                                     0 
                                  severe_decelerations 
                                                     0 
                              prolongued_decelerations 
                                                     0 
                       abnormal_short_term_variability 
                                                     0 
                  mean_value_of_short_term_variability 
                                                     0 
percentage_of_time_with_abnormal_long_term_variability 
                                                     0 
                   mean_value_of_long_term_variability 
                                                     0 
                                       histogram_width 
                                                     0 
                                         histogram_min 
                                                     0 
                                         histogram_max 
                                                     0 
                             histogram_number_of_peaks 
                                                     0 
                            histogram_number_of_zeroes 
                                                     0 
                                        histogram_mode 
                                                     0 
                                        histogram_mean 
                                                     0 
                                      histogram_median 
                                                     0 
                                    histogram_variance 
                                                     0 
                                    histogram_tendency 
                                                     0 
                                          fetal_health 
                                                     0 </code></pre>
</div>
</div>
<p>There are no missing values in the dataframe so I will not be doing data imputation for NAs.</p>
<p>Look at dependent variable:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> fetal_health))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Number of individuals in each category </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(fet_df<span class="sc">$</span>fetal_health)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
   1    2    3 
1655  295  176 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#percent of observations belonging to each category</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>(<span class="fu">table</span>(fet_df<span class="sc">$</span>fetal_health))<span class="sc">/</span><span class="dv">2126</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
         1          2          3 
0.77845720 0.13875823 0.08278457 </code></pre>
</div>
</div>
<p>There are 1655 normal cases (‘1’, 77.8%), 295 suspect cases (‘2’, 13.9%), and 176 pathological cases (‘3’, 8.3%), indicating an unbalanced outcome variable.</p>
<p>Looking at correlations between independent variables and outcome class:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>g1<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> baseline.value))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>g2<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> accelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>g3<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> fetal_movement))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>g4<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> uterine_contractions))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>g5<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> light_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>g6<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> severe_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>g7<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> prolongued_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>g8<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> abnormal_short_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>g9<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> mean_value_of_short_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>g10<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> percentage_of_time_with_abnormal_long_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>g11<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_width))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>g12<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> mean_value_of_long_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>g13<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_min))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>g14<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_max))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>g15<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_number_of_peaks))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>g16<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_number_of_zeroes))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>g17<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_mode))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>g18<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_mean))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>g19<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_median))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>g20<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_variance))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>g21<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_tendency))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, g11)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g12, g13, g14, g15, g16, g17, g18, g19, g20, g21)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-8-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Looking for outliers in independent variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>g1<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>baseline.value))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>g2<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>accelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>g3<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>fetal_movement))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>g4<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>uterine_contractions))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>g5<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>light_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>g6<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>severe_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>g7<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>prolongued_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>g8<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>abnormal_short_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>g9<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>mean_value_of_short_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>g10<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>percentage_of_time_with_abnormal_long_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>g11<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_width))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>g12<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>mean_value_of_long_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>g13<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_min))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>g14<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_max))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>g15<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_number_of_peaks))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>g16<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_number_of_zeroes))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>g17<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_mode))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>g18<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_mean))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>g19<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_median))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>g20<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_variance))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>g21<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_tendency))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g1, g2, g3, g4, g5, g6, g7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g8, g9, g10, g11, g12, g13, g14)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-9-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g15, g16, g17, g18, g19, g20, g21)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-9-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>There may be outliers based on some of the variables. I will run models on sets with all observations, but also try running it on data where the mean is imputed for the outliers to see if this makes a difference in model performance.</p>
<section id="creating-dummy-variables-from-histogram-tendency-variable" class="level2">
<h2 class="anchored" data-anchor-id="creating-dummy-variables-from-histogram-tendency-variable">Creating Dummy Variables from Histogram Tendency Variable</h2>
<p>Since analysis will be done in python, I need categorical variables coded as dummy variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span><span class="fu">mutate</span>(fet_df, <span class="at">histogram_tendency=</span>(<span class="fu">case_when</span>(</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">~</span> <span class="st">"negative"</span>,</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="dv">0</span> <span class="sc">~</span> <span class="st">"zero"</span>,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="dv">1</span> <span class="sc">~</span> <span class="st">"positive"</span>)))</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#using fastDummies package</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span> <span class="fu">dummy_cols</span>(fet_df, <span class="at">select_columns =</span> <span class="st">'histogram_tendency'</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dplyr<span class="sc">::</span><span class="fu">select</span>(fet_df, <span class="st">'histogram_tendency_negative'</span>, <span class="st">'histogram_tendency_positive'</span>, <span class="st">'histogram_tendency_zero'</span>), <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  histogram_tendency_negative histogram_tendency_positive
1                           0                           1
2                           0                           0
3                           0                           0
4                           0                           1
5                           0                           1
  histogram_tendency_zero
1                       0
2                       1
3                       1
4                       0
5                       0</code></pre>
</div>
</div>
</section>
<section id="creating-a-binary-outcome-variables" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-binary-outcome-variables">Creating a Binary Outcome Variables</h2>
<p>As I ran the models, I realized all models have a difficult time detecting suspect cases in particular. I combined suspect and pathological classes into a binary variable to see if this might improve performance when it comes to detecting these categories.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#mutating outcome to be binary 1= normal, 2= suspect &amp; pathological. New outcome column is called fetal_health_bin</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#case_when does not work well with factors, so I converted to characters and then back to factors</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.character</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Mutate into new binary outcome column fetal_health_bin (0=normal, 1= flagged cases)</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span>fet_df <span class="sc">%&gt;%</span> </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fetal_health_bin=</span><span class="fu">case_when</span>(</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  fetal_health<span class="sc">==</span> <span class="st">"1"</span> <span class="sc">~</span> <span class="st">"0"</span>,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  fetal_health <span class="sc">==</span> <span class="st">"2"</span> <span class="sc">|</span> fetal_health <span class="sc">==</span> <span class="st">"3"</span> <span class="sc">~</span> <span class="st">"1"</span>))</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">#fix classes of mutated columns</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health_bin<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health_bin)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-ordered-factors-for-3-class-outcome" class="level2">
<h2 class="anchored" data-anchor-id="creating-ordered-factors-for-3-class-outcome">Creating Ordered Factors for 3 Class Outcome:</h2>
<p>I also tested an ordered factor outcome category throughout runs, but to save space and time running the code I removed this from the analysis. Ordering the outcome factors generally resulted in the same outcome as for unordered classes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#trying out ordered factors</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health_fac <span class="ot">&lt;-</span> <span class="fu">factor</span>(fet_df<span class="sc">$</span>fetal_health, <span class="at">ordered =</span> <span class="cn">TRUE</span>, </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                                <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"1"</span>, <span class="st">"2"</span>, <span class="st">"3"</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking classes of new columns</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(fet_df<span class="sc">$</span>fetal_health_fac)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "ordered" "factor" </code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(fet_df<span class="sc">$</span>fetal_health)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "factor"</code></pre>
</div>
</div>
</section>
<section id="splitting-the-data" class="level2">
<h2 class="anchored" data-anchor-id="splitting-the-data">Splitting the Data</h2>
<p>I am setting aside the test (hold-out) set for use after cross-validation/ hyperparameter optimization. The training set has 1488 observations (70% of the data) and the test set has 638 observations (30% of the data).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create ID column</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>id<span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(fet_df)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co">#use 70% of dataset as training set and 30% as test set </span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> fet_df <span class="sc">%&gt;%</span> <span class="fu">sample_frac</span>(<span class="fl">0.7</span>) </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> <span class="fu">anti_join</span>(fet_df, train, <span class="at">by =</span> <span class="st">'id'</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking dimensions of split data</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1488   28</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 638  28</code></pre>
</div>
</div>
<p>The rest of the data preprocessing (scaling and outlier imputing) will be done within each cross-validation split using sci-kit learn’s pipeline.</p>
</section>
</section>
<section id="evaluation-metric" class="level1">
<h1>Evaluation Metric</h1>
<p>A metric that places importance on the detection of categories “suspect” (2) and “pathological” (3) is going to be very important so more caution and attention will be paid to these higher-risk cases. In other words, false negatives are likely to be more harmful than false positives. For instance, we can get very good accuracy score if we are very successful in classifying normal cases but less successful in detecting pathological and suspect cases.</p>
<p>In addition to macro f1 score, I will consider by-class f1 scores to ensure the model is performing sufficiently on suspect and pathological cases.</p>
</section>
<section id="fit-models" class="level1">
<h1>Fit Models</h1>
<section id="python-set-up" class="level3">
<h3 class="anchored" data-anchor-id="python-set-up">Python Set-Up</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn <span class="im">as</span> sklearn</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> linear_model</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Opening R objects with reticulate/Python</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>r.train</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>test<span class="op">=</span>r.test</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking class of outcome variable</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CategoricalDtype(categories=['1', '2', '3'], ordered=False)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health_fac'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CategoricalDtype(categories=['1', '2', '3'], ordered=True)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health_bin'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CategoricalDtype(categories=['0', '1'], ordered=False)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting subsets for x and y variables</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>train_x<span class="op">=</span>train[[<span class="st">'baseline.value'</span>,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="st">'accelerations'</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="st">'fetal_movement'</span>,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="st">'uterine_contractions'</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="st">'light_decelerations'</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="st">'severe_decelerations'</span>,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="st">'prolongued_decelerations'</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="st">'abnormal_short_term_variability'</span>,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_short_term_variability'</span>,</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="st">'percentage_of_time_with_abnormal_long_term_variability'</span>,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_long_term_variability'</span>,</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_width'</span>,</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_min'</span>,</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_max'</span>,</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_peaks'</span>,</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_zeroes'</span>,</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mode'</span>,</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mean'</span>,</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_median'</span>,</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_variance'</span>,</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_negative'</span>,</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_zero'</span>,</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_positive'</span>]]</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for 3 Classes</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>train_y<span class="op">=</span>train[[<span class="st">'fetal_health'</span>]]</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Ordered 3 Classes</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>train_y_fac<span class="op">=</span>train[[<span class="st">'fetal_health_fac'</span>]]</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Binary</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>train_y_bin<span class="op">=</span>train[[<span class="st">'fetal_health_bin'</span>]]</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="co">#convert data type from matrix to numpy ndarray</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>train_y<span class="op">=</span>train_y.values.ravel()</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>train_y_fac<span class="op">=</span>train_y_fac.values.ravel()</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>train_y_bin<span class="op">=</span>train_y_bin.values.ravel()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="defining-a-function-to-remove-outliers-based-on-z-score" class="level3">
<h3 class="anchored" data-anchor-id="defining-a-function-to-remove-outliers-based-on-z-score">Defining a Function to Remove Outliers Based on Z-score</h3>
<p>I used ChatGPT to help with this code. I still need to learn more about working with Numpy arrays and Pandas data frames but this eventually helped me figure out a function that could be implemented with Scikit-learn’s pipeline.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">#changing class of data frame to work with Function Transformer</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>np.array(train) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([[135.0, 0.001, 0.002, ..., '0', '1', 450],
       [139.0, 0.0, 0.007, ..., '1', '2', 346],
       [146.0, 0.0, 0.003, ..., '1', '3', 336],
       ...,
       [115.0, 0.006, 0.0, ..., '0', '1', 1275],
       [138.0, 0.0, 0.0, ..., '0', '1', 843],
       [122.0, 0.005, 0.0, ..., '0', '1', 931]], dtype=object)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#This code (from ChatGPT) transforms a function to work within Pipeline</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ElementWiseFunctionTransformer(BaseEstimator, TransformerMixin):</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, func):</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.func <span class="op">=</span> func</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X):</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.func(X)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Defining a function that replaces standardized observations with a z-score greater than the absolute value of 3 with 0 (mean). Observations will be standardized in the previous step in the pipe</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace_greater_than_abs_three(arr):</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.where(np.<span class="bu">abs</span>(arr) <span class="op">&gt;</span> <span class="dv">3</span>, <span class="dv">0</span>, arr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="penalized-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="penalized-logistic-regression">Penalized Logistic Regression</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#import python modules</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="testing-l1-and-l2-penalty" class="level3">
<h3 class="anchored" data-anchor-id="testing-l1-and-l2-penalty">Testing l1 and l2 Penalty</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#setting parameters to be tested with GridSearchCV</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>{<span class="st">'log_l__C'</span>: [<span class="fl">0.01</span>,<span class="fl">0.1</span>,<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>],</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="st">'log_l__penalty'</span>: [<span class="st">'l1'</span>, <span class="st">'l2'</span>]} <span class="co"># testing l1 and l2 penalty</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">#define pipeline</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>log_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'log_l'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>))])</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">#define pipeline that also removes outliers</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>log_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'log_l'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>))])</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Apply Grid Search</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>GS_log <span class="op">=</span> GridSearchCV(log_pipe, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#with outliers</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>GS_log_no_out <span class="op">=</span> GridSearchCV(log_pipe_no_out, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#with outliers imputed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using the pipeline should apply transformations at each fold to avoid data leakage and get more accurate evaluation metrics.</p>
</section>
<section id="defining-a-function-to-return-macro-f1-scores-and-by-class-f1-scores" class="level3">
<h3 class="anchored" data-anchor-id="defining-a-function-to-return-macro-f1-scores-and-by-class-f1-scores">Defining a Function to Return Macro f1 Scores and By-Class F1 Scores</h3>
<p>Below I define a function that takes in the outcome variable (y) and pre-defined GridSearchCV object and outputs macro f1 and by-class f1 scores</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> CV_F1_function(GS_object, outcome):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  random.seed(<span class="dv">3</span>) <span class="co"># set seed each time the algorithm is run for reproducibility</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#print best parameters and macro f1</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>  best_GS<span class="op">=</span>GS_object.fit(train_x, outcome) <span class="co">#finds the best parameters</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(best_GS.best_params_)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Best Macro F1:  </span><span class="sc">{</span>best_GS<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Print by-class f1 scores </span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>  pred1 <span class="op">=</span> cross_val_predict(best_GS.best_estimator_, train_x, outcome, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#plugs in best parameters</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>  f1_class <span class="op">=</span> f1_score(outcome, pred1, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculates by-class f1 scores</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(f1_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I use the above function to determine best parameters and optimize macro f1 scores for our data with outliers and with the outliers removed and imputed with the mean (0). This function returns optimized parameters, macro f1 scores, and by-class f1 scores (in the order: normal, suspect, pathological). I use this function throughout the rest of this document.</p>
<p>Plugging logistic regression grid search objects into function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_l__C': 1, 'log_l__penalty': 'l1'}
Best Macro F1:  0.8194031154528476
[0.9524618  0.70952381 0.8       ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_no_out, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes with x variable outliers removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_l__C': 500, 'log_l__penalty': 'l2'}
Best Macro F1:  0.7851217297163775
[0.94282084 0.67990074 0.72641509]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_l__C': 1000, 'log_l__penalty': 'l1'}
Best Macro F1:  0.8584997817538043
[0.9407282  0.77198697]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome with x variable outliers removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_l__C': 10, 'log_l__penalty': 'l1'}
Best Macro F1:  0.8374660860773042
[0.93316413 0.74183007]</code></pre>
</div>
</div>
<p>Our best macro f1 score for the 3 class unordered outcome (outliers kept) is 0.8194 where the f1 for “normal” is 0.952, 0.7095 for “suspect”, and 0.8 for “pathological”. The optimized parameters are an l1 penalty and C=1 (C is 1/lambda, so a small C indicates a large penalty).</p>
<p>For the binary outcome, out best f1 score is 0.8585 (occurs when outliers are kept) with an f1 for normal of 0.9416 and for the suspect/pathological cases 0.7752. The optimized C is 100, (a smaller penalty than for the 3 class outcome) and once again, the l1 penalty.</p>
</section>
</section>
<section id="elastic-net-regularization" class="level2">
<h2 class="anchored" data-anchor-id="elastic-net-regularization">Elastic Net Regularization</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>{<span class="st">'log_net__l1_ratio'</span>: [<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="dv">1</span>], <span class="co">#1 indicates full f1 penalty </span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="st">'log_net__C'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="dv">10</span>, <span class="dv">100</span>]} <span class="co"># tests 20 values of C between 0 and 4 on the log scale}</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>log_net <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>log_net_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'log_net'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>))])</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>log_net_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'log_net'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>))])</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>GS_log_net <span class="op">=</span> GridSearchCV(log_net_pipe, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>GS_log_net_no_out <span class="op">=</span> GridSearchCV(log_net_pipe_no_out, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_net__C': 1.0, 'log_net__l1_ratio': 0.9}
Best Macro F1:  0.8194031154528476
[0.9520577  0.70644391 0.8       ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_net__C': 1.0, 'log_net__l1_ratio': 0.7}
Best Macro F1:  0.7854264924167683
[0.94296578 0.68304668 0.73267327]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_net__C': 100, 'log_net__l1_ratio': 0.2}
Best Macro F1:  0.8584997817538043
[0.94157494 0.7752443 ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net_no_out, outcome<span class="op">=</span>train_y_bin)<span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'log_net__C': 10, 'log_net__l1_ratio': 0.2}
Best Macro F1:  0.8374660860773042
[0.93316413 0.74183007]</code></pre>
</div>
</div>
<p>Again, our best macro f1 score for the unordered 3 class outcome (outliers kept) is 0.8194. The optimized C is still 1, and the l1 ratio is 0.9, indicating a stronger l1 penalty performs better. This is consistent with the previous runs finding the l1 penalty outperformed the l2 penalty. For the binary outcome, the macro f1 score is 0.8589. This is very close to the results from the previous section. For simplicity’s sake I will only test the optimized parameters with the l1 penalty from the previous section on the final test set.</p>
</section>
<section id="boosting" class="level2">
<h2 class="anchored" data-anchor-id="boosting">Boosting</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> FunctionTransformer</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a><span class="co">#While it is unnecessary to scale data for boosting, I include it so we can use it to remove outliers in the next pipeline. Scaling the data should not affect model performance.</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>xgb_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'multi:softprob'</span>))]) <span class="co">#multi::softporb is used for multiclass outcome variables</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>xgb_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span> <span class="st">'multi:softprob'</span>))]) </span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>xgb_pipe_bin <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'binary:logistic'</span>))]) <span class="co">#binary:logisitic is used for binary outcome variables</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>xgb_pipe_no_out_bin <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span> <span class="st">'binary:logistic'</span>))]) </span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a><span class="co">#setting parameters to grid search</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__n_estimators"</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">1000</span>], <span class="co">#while more trees could increase performance slightly for some models, this is too time consuming to run</span></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__learning_rate"</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>],</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__max_depth"</span>: [<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>] <span class="co">#max depth of a tree... I tried to tune to higher depths however this was very time consuming to run and didn't provide much in return/ could possibly lead to overfitting</span></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>}<span class="co">#setting parameters to grid search</span></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class outcome labels (0,1,2, work with xgboost as opposed to 1,2,3)</span></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>train_yb <span class="op">=</span> le.fit_transform(train_y)</span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>train_yb_fac <span class="op">=</span> le.fit_transform(train_y_fac)</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class of binary outcome to work with xgboost</span></span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>train_yb_bin <span class="op">=</span> le.fit_transform(train_y_bin)</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a><span class="co">#Implementing grid search with cross validation</span></span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>GS_xgb<span class="op">=</span> GridSearchCV(xgb_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a>GS_xgb_no_out<span class="op">=</span> GridSearchCV(xgb_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a>GS_xgb_bin<span class="op">=</span> GridSearchCV(xgb_pipe_bin, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb63-39"><a href="#cb63-39" aria-hidden="true" tabindex="-1"></a>GS_xgb_no_out_bin<span class="op">=</span> GridSearchCV(xgb_pipe_no_out_bin, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb, outcome<span class="op">=</span>train_yb) <span class="co">#3 Classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'xgb__learning_rate': 0.5, 'xgb__max_depth': 8, 'xgb__n_estimators': 50}
Best Macro F1:  0.908639338113707
[0.97113752 0.84367246 0.9124424 ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_no_out, outcome<span class="op">=</span>train_yb) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'xgb__learning_rate': 1, 'xgb__max_depth': 8, 'xgb__n_estimators': 300}
Best Macro F1:  0.8891457194425483
[0.97164621 0.81518987 0.88073394]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_bin, outcome<span class="op">=</span>train_yb_bin) <span class="co">#Binary Outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'xgb__learning_rate': 0.1, 'xgb__max_depth': 8, 'xgb__n_estimators': 300}
Best Macro F1:  0.9328886201134079
[0.97193878 0.89423077]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_no_out_bin, outcome<span class="op">=</span>train_yb_bin) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'xgb__learning_rate': 0.1, 'xgb__max_depth': 6, 'xgb__n_estimators': 1000}
Best Macro F1:  0.9353604956079307
[0.97274276 0.89808917]</code></pre>
</div>
</div>
<p>These are the best performing models so far. The model with the binary outcome class (with outliers removed) performs fairly well on the suspect/pathological outcome class (macro f1= 0.935, f1 for “normal”=0.972, and f1 for “suspect/pathological”=0.898).</p>
</section>
<section id="support-vector-machines-svm" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machines-svm">Support Vector Machines (SVM)</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>params<span class="op">=</span> {</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__C'</span>: [<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">200</span>], <span class="co">#misclassification error term</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__gamma'</span>: [<span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>, <span class="fl">0.001</span>], <span class="co">#distance of points to decision boundary being considered</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__kernel'</span>: [<span class="st">'rbf'</span>, <span class="st">'poly'</span>, <span class="st">'sigmoid'</span>, <span class="st">'linear'</span>]</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>svm_cl_pipe <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'svm'</span>, svm.SVC())])</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>svm_cl_pipe_no_out <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'svm'</span>, svm.SVC())])</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>GS_svm<span class="op">=</span> GridSearchCV(svm_cl_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>GS_svm_no_out<span class="op">=</span> GridSearchCV(svm_cl_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm, outcome<span class="op">=</span>train_y) <span class="co">#Unordered 3 Classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}
Best Macro F1:  0.8468817212083832
[0.95939086 0.73658537 0.85148515]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}
Best Macro F1:  0.8376867178470627
[0.95379398 0.71921182 0.8436019 ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}
Best Macro F1:  0.904418810931511
[0.96006797 0.8488746 ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}
Best Macro F1:  0.8993948141236142
[0.95737425 0.84126984]</code></pre>
</div>
</div>
<p>Again the 3 class model has trouble detecting suspect cases, so in this case, I might prefer the binary outcome model (where suspect and pathological classes combined f1 score is 0.8489.) Boosting still performs better for both the three class and binary outcome variables.</p>
</section>
<section id="k-nearest-neighbors-knn" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</h2>
<p>Finally I tested K nearest neighbors to see if a high variance model (low bias) may perform better than boosting. This is not the case.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">'knn__n_neighbors'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>]}</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>knn_pipe <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'knn'</span>, KNeighborsClassifier())])</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>knn_pipe_no_out <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'knn'</span>, KNeighborsClassifier())])</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>GS_knn<span class="op">=</span> GridSearchCV(knn_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>GS_knn_no_out<span class="op">=</span> GridSearchCV(knn_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'knn__n_neighbors': 1}
Best Macro F1:  0.8164438106575634
[0.94661017 0.65835411 0.84651163]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'knn__n_neighbors': 3}
Best Macro F1:  0.7970359617201562
[0.94745621 0.66666667 0.77832512]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'knn__n_neighbors': 3}
Best Macro F1:  0.8756797607140687
[0.9510665 0.8      ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Outliers Removed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'knn__n_neighbors': 3}
Best Macro F1:  0.8781885851854287
[0.95130143 0.8047138 ]</code></pre>
</div>
</div>
</section>
<section id="final-model-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="final-model-evaluation">Final Model Evaluation</h2>
<section id="test-set-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="test-set-pre-processing">Test set pre-processing</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Test set pre-processing</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting subsets for x and y variables</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>test_x<span class="op">=</span>test[[<span class="st">'baseline.value'</span>,</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="st">'accelerations'</span>,</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="st">'fetal_movement'</span>,</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="st">'uterine_contractions'</span>,</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="st">'light_decelerations'</span>,</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a><span class="st">'severe_decelerations'</span>,</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="st">'prolongued_decelerations'</span>,</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="st">'abnormal_short_term_variability'</span>,</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_short_term_variability'</span>,</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="st">'percentage_of_time_with_abnormal_long_term_variability'</span>,</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_long_term_variability'</span>,</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_width'</span>,</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_min'</span>,</span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_max'</span>,</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_peaks'</span>,</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_zeroes'</span>,</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mode'</span>,</span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mean'</span>,</span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_median'</span>,</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_variance'</span>,</span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_negative'</span>,</span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_zero'</span>,</span>
<span id="cb90-26"><a href="#cb90-26" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_positive'</span>]]</span>
<span id="cb90-27"><a href="#cb90-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-28"><a href="#cb90-28" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for 3 Classes</span></span>
<span id="cb90-29"><a href="#cb90-29" aria-hidden="true" tabindex="-1"></a>test_y<span class="op">=</span>test[[<span class="st">'fetal_health'</span>]]</span>
<span id="cb90-30"><a href="#cb90-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-31"><a href="#cb90-31" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Binary</span></span>
<span id="cb90-32"><a href="#cb90-32" aria-hidden="true" tabindex="-1"></a>test_y_bin<span class="op">=</span>test[[<span class="st">'fetal_health_bin'</span>]]</span>
<span id="cb90-33"><a href="#cb90-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-34"><a href="#cb90-34" aria-hidden="true" tabindex="-1"></a><span class="co">#convert data type from matrix to numpy npdarray</span></span>
<span id="cb90-35"><a href="#cb90-35" aria-hidden="true" tabindex="-1"></a>test_y<span class="op">=</span>test_y.values.ravel()</span>
<span id="cb90-36"><a href="#cb90-36" aria-hidden="true" tabindex="-1"></a>test_y_bin<span class="op">=</span>test_y_bin.values.ravel()</span>
<span id="cb90-37"><a href="#cb90-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-38"><a href="#cb90-38" aria-hidden="true" tabindex="-1"></a><span class="co">#Standardize Test Data Based on column means and standard deviations of training set</span></span>
<span id="cb90-39"><a href="#cb90-39" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> (test_x <span class="op">-</span> train_x.mean()) <span class="op">/</span> train_x.std()</span>
<span id="cb90-40"><a href="#cb90-40" aria-hidden="true" tabindex="-1"></a>test_x_no_out<span class="op">=</span>replace_greater_than_abs_three(test_x) <span class="co">#create test df with outliers imputed with the mean (0)</span></span>
<span id="cb90-41"><a href="#cb90-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-42"><a href="#cb90-42" aria-hidden="true" tabindex="-1"></a><span class="co">#For simplicity, all variables (including dummy variables) have been standardized (the pipeline did this as well). While unnecessary, this should not affect results. </span></span>
<span id="cb90-43"><a href="#cb90-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-44"><a href="#cb90-44" aria-hidden="true" tabindex="-1"></a><span class="co">#Standardize full training data</span></span>
<span id="cb90-45"><a href="#cb90-45" aria-hidden="true" tabindex="-1"></a>train_x_st <span class="op">=</span> (train_x <span class="op">-</span> train_x.mean()) <span class="op">/</span> train_x.std()</span>
<span id="cb90-46"><a href="#cb90-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-47"><a href="#cb90-47" aria-hidden="true" tabindex="-1"></a>train_x_st_no_out<span class="op">=</span>replace_greater_than_abs_three(train_x_st) <span class="co">#create training df with outliers imputed with the mean</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Classes, Outliers Kept: l1 penalty with C=1</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>log_final_mod<span class="op">=</span>LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, C<span class="op">=</span><span class="fl">1.0</span>, penalty<span class="op">=</span><span class="st">'l1'</span>) <span class="co">#fit model with optimized hyperparameters</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>log_final_mod.fit(train_x_st, train_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(penalty='l1', solver='saga', tol=0.006)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(penalty='l1', solver='saga', tol=0.006)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>log_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.7603825352102777</code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Kept: l1 penalty and C=500</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.9402229  0.58682635 0.75409836]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>log_final_mod_bin<span class="op">=</span>LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, C<span class="op">=</span><span class="dv">500</span>, penalty<span class="op">=</span><span class="st">'l1'</span>) <span class="co">#fit model with optimized hyperparameters</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>log_final_mod.fit(train_x_st, train_y_bin)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(penalty='l1', solver='saga', tol=0.006)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(penalty='l1', solver='saga', tol=0.006)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>log_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8712133867914023</code></pre>
</div>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.94105691 0.80136986]</code></pre>
</div>
</div>
</section>
<section id="boosting-1" class="level3">
<h3 class="anchored" data-anchor-id="boosting-1">Boosting</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class outcome labels (0,1,2, work with xgboost as opposed to 1,2,3)</span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>test_yb <span class="op">=</span> le.fit_transform(test_y)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class of binary outcome to work with xgboost</span></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>test_yb_bin <span class="op">=</span> le.fit_transform(test_y_bin)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class, Outliers Kept: learning_rate= 0.5, max_depth= 8, n_estimators= 50</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>boosting_final_mod<span class="op">=</span> xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'multi:softprob'</span>, learning_rate<span class="op">=</span> <span class="fl">0.5</span>, max_depth<span class="op">=</span> <span class="dv">8</span>, n_estimators<span class="op">=</span> <span class="dv">50</span>)</span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>boosting_final_mod.fit(train_x_st, train_yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.5, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=50, n_jobs=None, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.5, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=50, n_jobs=None, num_parallel_tree=None,
              objective='multi:softprob', predictor=None, ...)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>boosting_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_yb, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9241664606695282</code></pre>
</div>
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_yb, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Imputed: learning_rate=0.1, max_depth= 6, n_estimators= 1000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.97341513 0.8452381  0.95384615]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>boosting_final_mod_bin<span class="op">=</span> xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'binary:logistic'</span>, learning_rate<span class="op">=</span> <span class="fl">0.1</span>, max_depth<span class="op">=</span> <span class="dv">6</span>, n_estimators<span class="op">=</span> <span class="dv">1000</span>)</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>boosting_final_mod_bin.fit(train_x_st_no_out, train_yb_bin)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=1000, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked=""><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=1000, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>boosting_final_mod_bin.predict(test_x_no_out) <span class="co">#make predictions on test set</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_yb_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9474616049738545</code></pre>
</div>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_yb_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.97546012 0.91946309]</code></pre>
</div>
</div>
</section>
<section id="support-vector-machines" class="level3">
<h3 class="anchored" data-anchor-id="support-vector-machines">Support Vector Machines</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class Outcome, Outliers Kept: C=10, gamma= 0.1, kernel= 'rbf'</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>svm_final_mod<span class="op">=</span>svm.SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span> <span class="fl">0.1</span>, kernel<span class="op">=</span> <span class="st">'rbf'</span>)</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>svm_final_mod.fit(train_x_st, train_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(C=10, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked=""><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(C=10, gamma=0.1)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>svm_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8413941228023978</code></pre>
</div>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome Outliers Kept: C=10, gamma= 0.1, kernel= 'rbf'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.95634518 0.78212291 0.78571429]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>svm_final_mod_bin<span class="op">=</span>svm.SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span> <span class="fl">0.1</span>, kernel<span class="op">=</span> <span class="st">'rbf'</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>svm_final_mod_bin.fit(train_x_st, train_y_bin)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(C=10, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked=""><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(C=10, gamma=0.1)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>svm_final_mod_bin.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9124360082897572</code></pre>
</div>
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.9591002  0.86577181]</code></pre>
</div>
</div>
</section>
<section id="k-nearest-neighbors" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors">K-Nearest Neighbors</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class, Outliers Kept: n-neighbors= 1</span></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>knn_final_mod<span class="op">=</span>KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>knn_final_mod.fit(train_x_st, train_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>knn_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.7923969108297486</code></pre>
</div>
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Imputed: n-neighbors=3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.94512195 0.65895954 0.77310924]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>knn_final_mod_bin<span class="op">=</span>KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>knn_final_mod_bin.fit(train_x_st_no_out, train_y_bin)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked=""><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>knn_final_mod_bin.predict(test_x_no_out) <span class="co">#make predictions on test set</span></span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8512755510876059</code></pre>
</div>
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.93612774 0.76642336]</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="compare-models" class="level1">
<h1>Compare Models</h1>
<p><strong>Three-Class F1 Scores (Macro, By-Class):</strong></p>
<p>Logistic Regression: 0.760 [0.9402229, 0.58682635, 0.75409836]</p>
<p>Boosting: 0.924 [0.97341513, 0.8452381, 0.95384615]</p>
<p>SVM: 0.841 [0.95634518, 0.78212291, 0.78571429]</p>
<p>KNN: 0.792 [0.94512195, 0.65895954, 0.77310924]</p>
<p><strong>Binary Outcome F1 Scores (Macro, By-Class):</strong></p>
<p>Logistic Regression: 0.869 [0.94010152 0.79725086]</p>
<p>Boosting: 0.947 [0.97546012, 0.91946309]</p>
<p>SVM: 0.912 [0.9591002, 0.86577181]</p>
<p>KNN: 0.851 [0.93612774 0.76642336]</p>
<p>The best performing model for both a three-class outcome and a binary outcome was the model created with XGBoost. These models actually performed slightly better when trained on the full training set and tested on the held-out test set than they did during cross validation. This is likely because the final model was trained on a larger dataset. Boosting slowly learns through a sequential algorithm where trees are fit on residuals from the previous tree. Because we are fitting many trees, this algorithm is less prone to overfitting. While XGBoost reduces bias and can produce very good predictions, this model is less interpretable than other models such as logistic regression.</p>
<p>Logistic regression is the most biased model used in this analysis. Because this model has low flexibility it could not learn as much from the training data as models like boosting, SVM and KNN can. However, this is likely the most interpretable model from this analysis. While interpretable, the logistic regression model does not perform well enough to be used, especially given performance on the “suspect” and “pathological” cases.</p>
<p>After boosting, the best performing model was support vector machines (SVM). SVM does a better job classifying “suspect” and “pathological” cases than KNN and logisitic regression, especially on a binary outcome variable. One advantage of SVM is we can impose a softer margin by increasing C (increasing bias), which likely helped SVM learn the nuances of classification of these categories without increasing the variance. SVM also allows us to model highly non-linear relationships (this is likely the case for out data given logistic regression did not perform well). In our case, the optimal kernel was a radial kernel which can perform well in a dataset of higher dimensions.</p>
<p>Finally I tested K-Nearest Neighbors to see if a low bias, high variance model could perform well given our data did not seem to follow a linear relationship. This was not the case, KNN performed similarly to logistic regression, suggesting a model that has a balance between bias and variance would work better with our data. KNN is also not very interpretable. KNN had the lowest score of all the models on the test set for the binary outcome class (and also a low score for the three class outcome) thus, it was likely overfitting to the training data (especially given the optimized k for the 3 class outcome was 1).</p>
</section>
<section id="ethical-implications" class="level1">
<h1>Ethical Implications</h1>
<p>While I was hoping to land on an interpretable model so one could easily interpret what may be flagging a case as “suspect” or “pathological”, in the case of CTGs, a better performing model is more important than an interpretable model.</p>
<p>While boosted models are not very interpretable, the performance is the best for both a 3-class outcome variable and a binary outcome variable.</p>
<p>In an outpatient setting, where there is more time to take a closer look at the CTGs, I might suggest using the boosted model with a binary outcome (macro f1= 0.947, f1 for class “normal”= 0.975, f1 for class “suspect/pathological”= 0.919”). This is because the “suspect” case is still difficult to detect in the three-class outcome, so the better f1 score for the combined outcome might be better for flagging suspect cases in addition to pathological cases. In an outpatient setting, the medical professional can then look closer at the flagged cases, interpret why they are being flagged and then class them as “suspect” or “pathological”. For a labor setting, time is more critical, and immediate flagging of pathological cases is more critical. In a labor setting, I would suggest using the boosted 3-class outcome since it performs better on the pathological cases (and suspect cases are not necessarily in need of immediate attention) (macro f1=0.924, f1 for “normal”= 0.973, f1 for “suspect”= 0.845, and f1 for “pathological”= 0.954).</p>
<p>Because in general, f1 scores for suspect and pathological classes are much lower than for normal, I am not sure I would ever feel comfortable with this model being deployed without a human medical professional also analyzing the CTG and making a decision for themselves. Finally, before being deployed, such a model should be trained on a much larger data set than was done in this analysis (to avoid overfitting).</p>
<p>While my original aim was to come up with a high-performing interpretable model, given the low f1 score for suspect/pathological classes, I would consider training a neural network/deep learning model in the future if such a model is able to achieve better performance. However, even if a much higher performing, neural network or other machine learning model is developed, it should not be deployed without people trained to read CTGs analyzing the document for themselves given the low interpretablilty of such an algorithm.</p>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>Dataset: Ayres de Campos et al.&nbsp;(2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318 (<a href="https://onlinelibrary.wiley.com/doi/10.1002/1520-6661(200009/10)9:5%3C311" class="uri">https://onlinelibrary.wiley.com/doi/10.1002/1520-6661(200009/10)9:5%3C311</a>::AID-MFM12%3E3.0.CO;2-9)</p>
<p>Cariotocography. (Accessed May 24, 2023). Wikipedia. <a href="https://en.wikipedia.org/wiki/Cardiotocography" class="uri">https://en.wikipedia.org/wiki/Cardiotocography</a>. Fetal Health Classification. (Accessed May 24, 2023).</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb131" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Machine Learning Final Project"</span></span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Emma Rasmussen"</span></span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Machine Learning to Interpret Cardiotocograms (CTGs)"</span></span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "05/22/2022"</span></span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "CTG_Output.jpeg"</span></span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-copy: true</span></span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-16"><a href="#cb131-16" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-17"><a href="#cb131-17" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb131-18"><a href="#cb131-18" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb131-19"><a href="#cb131-19" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb131-20"><a href="#cb131-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-21"><a href="#cb131-21" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> <span class="cn">TRUE</span>, <span class="at">warning=</span><span class="cn">FALSE</span>, <span class="at">message=</span><span class="cn">FALSE</span>)</span>
<span id="cb131-22"><a href="#cb131-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-23"><a href="#cb131-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb131-24"><a href="#cb131-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb131-25"><a href="#cb131-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb131-26"><a href="#cb131-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb131-27"><a href="#cb131-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VIM)</span>
<span id="cb131-28"><a href="#cb131-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lubridate)</span>
<span id="cb131-29"><a href="#cb131-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb131-30"><a href="#cb131-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb131-31"><a href="#cb131-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb131-32"><a href="#cb131-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb131-33"><a href="#cb131-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb131-34"><a href="#cb131-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb131-35"><a href="#cb131-35" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb131-36"><a href="#cb131-36" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MLmetrics)</span>
<span id="cb131-37"><a href="#cb131-37" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb131-38"><a href="#cb131-38" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb131-39"><a href="#cb131-39" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastDummies)</span>
<span id="cb131-40"><a href="#cb131-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-41"><a href="#cb131-41" aria-hidden="true" tabindex="-1"></a><span class="fu">virtualenv_create</span>(<span class="st">"MLFinal"</span>) <span class="co">#create virtual environment... per reticulate cheat sheet</span></span>
<span id="cb131-42"><a href="#cb131-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-43"><a href="#cb131-43" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"pandas"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb131-44"><a href="#cb131-44" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"numpy"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb131-45"><a href="#cb131-45" aria-hidden="true" tabindex="-1"></a><span class="fu">py_install</span>(<span class="st">"xgboost"</span>, <span class="at">env_name=</span><span class="st">"MLFinal"</span>)</span>
<span id="cb131-46"><a href="#cb131-46" aria-hidden="true" tabindex="-1"></a><span class="fu">conda_install</span>(<span class="st">"MLFinal"</span>, <span class="st">"scikit-learn"</span>)</span>
<span id="cb131-47"><a href="#cb131-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-48"><a href="#cb131-48" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"MLFinal"</span>)</span>
<span id="cb131-49"><a href="#cb131-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-50"><a href="#cb131-50" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>knit_engines<span class="sc">$</span><span class="fu">set</span>(<span class="at">python =</span></span>
<span id="cb131-51"><a href="#cb131-51" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span>eng_python) </span>
<span id="cb131-52"><a href="#cb131-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-53"><a href="#cb131-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-54"><a href="#cb131-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-55"><a href="#cb131-55" aria-hidden="true" tabindex="-1"></a><span class="fu"># Motivation</span></span>
<span id="cb131-56"><a href="#cb131-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-57"><a href="#cb131-57" aria-hidden="true" tabindex="-1"></a>Cardiotocograms (CTGs) are used during labor and late stage pregnancy to monitor fetal and maternal health. CTGs (also called electronic fetal monitoring, EFM) use ultrasound transducers to record fetal heart rate and Braxton Hicks contractions. CTGs can indicate if a fetus is at risk for hypoxia (lack of oxygen). Variables like histogram_mode (etc) are referring to fetal heart rate histograms. An example CTG is pictured below:</span>
<span id="cb131-58"><a href="#cb131-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-59"><a href="#cb131-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb131-60"><a href="#cb131-60" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"CTG_Output.jpeg"</span>) </span>
<span id="cb131-61"><a href="#cb131-61" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-62"><a href="#cb131-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-63"><a href="#cb131-63" aria-hidden="true" tabindex="-1"></a>Image Source: (Cardiotocography 2023)</span>
<span id="cb131-64"><a href="#cb131-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-65"><a href="#cb131-65" aria-hidden="true" tabindex="-1"></a>On the CTG, (A) shows fetal heartbeat, (B) shows fetal movement felt by the mother, (C) shows recorded fetal movement, and (D) shows uterine contractions.</span>
<span id="cb131-66"><a href="#cb131-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-67"><a href="#cb131-67" aria-hidden="true" tabindex="-1"></a>A fetus at risk for hypoxia is considered "pathological" and in need of immediate attention. Suspect cases may have one characteristic that strays from normal but are not at an immediate risk.</span>
<span id="cb131-68"><a href="#cb131-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-69"><a href="#cb131-69" aria-hidden="true" tabindex="-1"></a>In the fetal health data set used in this analysis, the classification into categories (normal (1), suspect (2), and pathological (3)) was done by "expert obstetricians" interpreting the CTG results (Ayres de Campos et al. 2000).</span>
<span id="cb131-70"><a href="#cb131-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-71"><a href="#cb131-71" aria-hidden="true" tabindex="-1"></a>The motivation behind creating a machine learning algorithm to interpret these CTGs is to:</span>
<span id="cb131-72"><a href="#cb131-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-73"><a href="#cb131-73" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Aid human interpretation of CTGs, make results more accessible to untrained individuals</span>
<span id="cb131-74"><a href="#cb131-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-75"><a href="#cb131-75" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Speed up human interpretation</span>
<span id="cb131-76"><a href="#cb131-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-77"><a href="#cb131-77" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Potentially help reduce biases in the medical system (for instance, discounting an individuals concerns based on race or ethnicity). An algorithm based on the variables in our dataset should not hold these biases.</span>
<span id="cb131-78"><a href="#cb131-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-79"><a href="#cb131-79" aria-hidden="true" tabindex="-1"></a>This document is created with R Markdown and uses R's 'reticulate' package to integrate Python code. Most visualizations and data cleaning is done in R, while the machine learning algorithms are run in Python.</span>
<span id="cb131-80"><a href="#cb131-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-81"><a href="#cb131-81" aria-hidden="true" tabindex="-1"></a><span class="fu"># Exploratory Data Analysis and Data Preprocessing</span></span>
<span id="cb131-82"><a href="#cb131-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-83"><a href="#cb131-83" aria-hidden="true" tabindex="-1"></a>Read in the Data:</span>
<span id="cb131-84"><a href="#cb131-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-87"><a href="#cb131-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-88"><a href="#cb131-88" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"fetal_health.csv"</span>)</span>
<span id="cb131-89"><a href="#cb131-89" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb131-90"><a href="#cb131-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-91"><a href="#cb131-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-92"><a href="#cb131-92" aria-hidden="true" tabindex="-1"></a>Look at size of data frame and summary statistics:</span>
<span id="cb131-93"><a href="#cb131-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-96"><a href="#cb131-96" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-97"><a href="#cb131-97" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(fet_df)</span>
<span id="cb131-98"><a href="#cb131-98" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fet_df)</span>
<span id="cb131-99"><a href="#cb131-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-100"><a href="#cb131-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-101"><a href="#cb131-101" aria-hidden="true" tabindex="-1"></a>The data has 2126 observations and 22 variables.</span>
<span id="cb131-102"><a href="#cb131-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-103"><a href="#cb131-103" aria-hidden="true" tabindex="-1"></a>Check for missing values:</span>
<span id="cb131-104"><a href="#cb131-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-107"><a href="#cb131-107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-108"><a href="#cb131-108" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(fet_df))</span>
<span id="cb131-109"><a href="#cb131-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-110"><a href="#cb131-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-111"><a href="#cb131-111" aria-hidden="true" tabindex="-1"></a>There are no missing values in the dataframe so I will not be doing data imputation for NAs.</span>
<span id="cb131-112"><a href="#cb131-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-113"><a href="#cb131-113" aria-hidden="true" tabindex="-1"></a>Look at dependent variable:</span>
<span id="cb131-114"><a href="#cb131-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-117"><a href="#cb131-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-118"><a href="#cb131-118" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> fetal_health))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>)</span>
<span id="cb131-119"><a href="#cb131-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-120"><a href="#cb131-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-121"><a href="#cb131-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-124"><a href="#cb131-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-125"><a href="#cb131-125" aria-hidden="true" tabindex="-1"></a><span class="co">#Number of individuals in each category </span></span>
<span id="cb131-126"><a href="#cb131-126" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb131-127"><a href="#cb131-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-128"><a href="#cb131-128" aria-hidden="true" tabindex="-1"></a><span class="co">#percent of observations belonging to each category</span></span>
<span id="cb131-129"><a href="#cb131-129" aria-hidden="true" tabindex="-1"></a>(<span class="fu">table</span>(fet_df<span class="sc">$</span>fetal_health))<span class="sc">/</span><span class="dv">2126</span></span>
<span id="cb131-130"><a href="#cb131-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-131"><a href="#cb131-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-132"><a href="#cb131-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-133"><a href="#cb131-133" aria-hidden="true" tabindex="-1"></a>There are 1655 normal cases ('1', 77.8%), 295 suspect cases ('2', 13.9%), and 176 pathological cases ('3', 8.3%), indicating an unbalanced outcome variable.</span>
<span id="cb131-134"><a href="#cb131-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-135"><a href="#cb131-135" aria-hidden="true" tabindex="-1"></a>Looking at correlations between independent variables and outcome class:</span>
<span id="cb131-136"><a href="#cb131-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-139"><a href="#cb131-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-140"><a href="#cb131-140" aria-hidden="true" tabindex="-1"></a>g1<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> baseline.value))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-141"><a href="#cb131-141" aria-hidden="true" tabindex="-1"></a>g2<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> accelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-142"><a href="#cb131-142" aria-hidden="true" tabindex="-1"></a>g3<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> fetal_movement))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-143"><a href="#cb131-143" aria-hidden="true" tabindex="-1"></a>g4<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> uterine_contractions))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-144"><a href="#cb131-144" aria-hidden="true" tabindex="-1"></a>g5<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> light_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-145"><a href="#cb131-145" aria-hidden="true" tabindex="-1"></a>g6<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> severe_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-146"><a href="#cb131-146" aria-hidden="true" tabindex="-1"></a>g7<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> prolongued_decelerations))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-147"><a href="#cb131-147" aria-hidden="true" tabindex="-1"></a>g8<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> abnormal_short_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-148"><a href="#cb131-148" aria-hidden="true" tabindex="-1"></a>g9<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> mean_value_of_short_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-149"><a href="#cb131-149" aria-hidden="true" tabindex="-1"></a>g10<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> percentage_of_time_with_abnormal_long_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-150"><a href="#cb131-150" aria-hidden="true" tabindex="-1"></a>g11<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_width))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-151"><a href="#cb131-151" aria-hidden="true" tabindex="-1"></a>g12<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> mean_value_of_long_term_variability))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-152"><a href="#cb131-152" aria-hidden="true" tabindex="-1"></a>g13<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_min))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-153"><a href="#cb131-153" aria-hidden="true" tabindex="-1"></a>g14<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_max))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-154"><a href="#cb131-154" aria-hidden="true" tabindex="-1"></a>g15<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_number_of_peaks))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-155"><a href="#cb131-155" aria-hidden="true" tabindex="-1"></a>g16<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_number_of_zeroes))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-156"><a href="#cb131-156" aria-hidden="true" tabindex="-1"></a>g17<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_mode))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-157"><a href="#cb131-157" aria-hidden="true" tabindex="-1"></a>g18<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_mean))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-158"><a href="#cb131-158" aria-hidden="true" tabindex="-1"></a>g19<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_median))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-159"><a href="#cb131-159" aria-hidden="true" tabindex="-1"></a>g20<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_variance))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-160"><a href="#cb131-160" aria-hidden="true" tabindex="-1"></a>g21<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span> histogram_tendency))<span class="sc">+</span><span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"count"</span>, <span class="fu">aes</span>(<span class="at">fill=</span>fetal_health))</span>
<span id="cb131-161"><a href="#cb131-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-162"><a href="#cb131-162" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, g11)</span>
<span id="cb131-163"><a href="#cb131-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-164"><a href="#cb131-164" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g12, g13, g14, g15, g16, g17, g18, g19, g20, g21)</span>
<span id="cb131-165"><a href="#cb131-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-166"><a href="#cb131-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-167"><a href="#cb131-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-168"><a href="#cb131-168" aria-hidden="true" tabindex="-1"></a>Looking for outliers in independent variables:</span>
<span id="cb131-169"><a href="#cb131-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-172"><a href="#cb131-172" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-173"><a href="#cb131-173" aria-hidden="true" tabindex="-1"></a>g1<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>baseline.value))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-174"><a href="#cb131-174" aria-hidden="true" tabindex="-1"></a>g2<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>accelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-175"><a href="#cb131-175" aria-hidden="true" tabindex="-1"></a>g3<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>fetal_movement))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-176"><a href="#cb131-176" aria-hidden="true" tabindex="-1"></a>g4<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>uterine_contractions))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-177"><a href="#cb131-177" aria-hidden="true" tabindex="-1"></a>g5<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>light_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-178"><a href="#cb131-178" aria-hidden="true" tabindex="-1"></a>g6<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>severe_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-179"><a href="#cb131-179" aria-hidden="true" tabindex="-1"></a>g7<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>prolongued_decelerations))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-180"><a href="#cb131-180" aria-hidden="true" tabindex="-1"></a>g8<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>abnormal_short_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-181"><a href="#cb131-181" aria-hidden="true" tabindex="-1"></a>g9<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>mean_value_of_short_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-182"><a href="#cb131-182" aria-hidden="true" tabindex="-1"></a>g10<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>percentage_of_time_with_abnormal_long_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-183"><a href="#cb131-183" aria-hidden="true" tabindex="-1"></a>g11<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_width))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-184"><a href="#cb131-184" aria-hidden="true" tabindex="-1"></a>g12<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>mean_value_of_long_term_variability))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-185"><a href="#cb131-185" aria-hidden="true" tabindex="-1"></a>g13<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_min))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-186"><a href="#cb131-186" aria-hidden="true" tabindex="-1"></a>g14<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_max))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-187"><a href="#cb131-187" aria-hidden="true" tabindex="-1"></a>g15<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_number_of_peaks))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-188"><a href="#cb131-188" aria-hidden="true" tabindex="-1"></a>g16<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_number_of_zeroes))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-189"><a href="#cb131-189" aria-hidden="true" tabindex="-1"></a>g17<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_mode))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-190"><a href="#cb131-190" aria-hidden="true" tabindex="-1"></a>g18<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_mean))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-191"><a href="#cb131-191" aria-hidden="true" tabindex="-1"></a>g19<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_median))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-192"><a href="#cb131-192" aria-hidden="true" tabindex="-1"></a>g20<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_variance))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-193"><a href="#cb131-193" aria-hidden="true" tabindex="-1"></a>g21<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>fet_df, <span class="fu">aes</span>(<span class="at">x=</span>fetal_health, <span class="at">y=</span>histogram_tendency))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span>
<span id="cb131-194"><a href="#cb131-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-195"><a href="#cb131-195" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g1, g2, g3, g4, g5, g6, g7)</span>
<span id="cb131-196"><a href="#cb131-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-197"><a href="#cb131-197" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g8, g9, g10, g11, g12, g13, g14)</span>
<span id="cb131-198"><a href="#cb131-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-199"><a href="#cb131-199" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(g15, g16, g17, g18, g19, g20, g21)</span>
<span id="cb131-200"><a href="#cb131-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-201"><a href="#cb131-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-202"><a href="#cb131-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-203"><a href="#cb131-203" aria-hidden="true" tabindex="-1"></a>There may be outliers based on some of the variables. I will run models on sets with all observations, but also try running it on data where the mean is imputed for the outliers to see if this makes a difference in model performance.</span>
<span id="cb131-204"><a href="#cb131-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-205"><a href="#cb131-205" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating Dummy Variables from Histogram Tendency Variable</span></span>
<span id="cb131-206"><a href="#cb131-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-207"><a href="#cb131-207" aria-hidden="true" tabindex="-1"></a>Since analysis will be done in python, I need categorical variables coded as dummy variables.</span>
<span id="cb131-208"><a href="#cb131-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-211"><a href="#cb131-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-212"><a href="#cb131-212" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span><span class="fu">mutate</span>(fet_df, <span class="at">histogram_tendency=</span>(<span class="fu">case_when</span>(</span>
<span id="cb131-213"><a href="#cb131-213" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">~</span> <span class="st">"negative"</span>,</span>
<span id="cb131-214"><a href="#cb131-214" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="dv">0</span> <span class="sc">~</span> <span class="st">"zero"</span>,</span>
<span id="cb131-215"><a href="#cb131-215" aria-hidden="true" tabindex="-1"></a>                                   histogram_tendency <span class="sc">==</span> <span class="dv">1</span> <span class="sc">~</span> <span class="st">"positive"</span>)))</span>
<span id="cb131-216"><a href="#cb131-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-217"><a href="#cb131-217" aria-hidden="true" tabindex="-1"></a><span class="co">#using fastDummies package</span></span>
<span id="cb131-218"><a href="#cb131-218" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span> <span class="fu">dummy_cols</span>(fet_df, <span class="at">select_columns =</span> <span class="st">'histogram_tendency'</span>)</span>
<span id="cb131-219"><a href="#cb131-219" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dplyr<span class="sc">::</span><span class="fu">select</span>(fet_df, <span class="st">'histogram_tendency_negative'</span>, <span class="st">'histogram_tendency_positive'</span>, <span class="st">'histogram_tendency_zero'</span>), <span class="dv">5</span>)</span>
<span id="cb131-220"><a href="#cb131-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-221"><a href="#cb131-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-222"><a href="#cb131-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-223"><a href="#cb131-223" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating a Binary Outcome Variables</span></span>
<span id="cb131-224"><a href="#cb131-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-225"><a href="#cb131-225" aria-hidden="true" tabindex="-1"></a>As I ran the models, I realized all models have a difficult time detecting suspect cases in particular. I combined suspect and pathological classes into a binary variable to see if this might improve performance when it comes to detecting these categories.</span>
<span id="cb131-226"><a href="#cb131-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-229"><a href="#cb131-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-230"><a href="#cb131-230" aria-hidden="true" tabindex="-1"></a><span class="co">#mutating outcome to be binary 1= normal, 2= suspect &amp; pathological. New outcome column is called fetal_health_bin</span></span>
<span id="cb131-231"><a href="#cb131-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-232"><a href="#cb131-232" aria-hidden="true" tabindex="-1"></a><span class="co">#case_when does not work well with factors, so I converted to characters and then back to factors</span></span>
<span id="cb131-233"><a href="#cb131-233" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.character</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb131-234"><a href="#cb131-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-235"><a href="#cb131-235" aria-hidden="true" tabindex="-1"></a><span class="co">#Mutate into new binary outcome column fetal_health_bin (0=normal, 1= flagged cases)</span></span>
<span id="cb131-236"><a href="#cb131-236" aria-hidden="true" tabindex="-1"></a>fet_df<span class="ot">&lt;-</span>fet_df <span class="sc">%&gt;%</span> </span>
<span id="cb131-237"><a href="#cb131-237" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fetal_health_bin=</span><span class="fu">case_when</span>(</span>
<span id="cb131-238"><a href="#cb131-238" aria-hidden="true" tabindex="-1"></a>  fetal_health<span class="sc">==</span> <span class="st">"1"</span> <span class="sc">~</span> <span class="st">"0"</span>,</span>
<span id="cb131-239"><a href="#cb131-239" aria-hidden="true" tabindex="-1"></a>  fetal_health <span class="sc">==</span> <span class="st">"2"</span> <span class="sc">|</span> fetal_health <span class="sc">==</span> <span class="st">"3"</span> <span class="sc">~</span> <span class="st">"1"</span>))</span>
<span id="cb131-240"><a href="#cb131-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-241"><a href="#cb131-241" aria-hidden="true" tabindex="-1"></a><span class="co">#fix classes of mutated columns</span></span>
<span id="cb131-242"><a href="#cb131-242" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health_bin<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health_bin)</span>
<span id="cb131-243"><a href="#cb131-243" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health<span class="ot">&lt;-</span><span class="fu">as.factor</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb131-244"><a href="#cb131-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-245"><a href="#cb131-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-246"><a href="#cb131-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-247"><a href="#cb131-247" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating Ordered Factors for 3 Class Outcome:</span></span>
<span id="cb131-248"><a href="#cb131-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-249"><a href="#cb131-249" aria-hidden="true" tabindex="-1"></a>I also tested an ordered factor outcome category throughout runs, but to save space and time running the code I removed this from the analysis. Ordering the outcome factors generally resulted in the same outcome as for unordered classes.</span>
<span id="cb131-250"><a href="#cb131-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-253"><a href="#cb131-253" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-254"><a href="#cb131-254" aria-hidden="true" tabindex="-1"></a><span class="co">#trying out ordered factors</span></span>
<span id="cb131-255"><a href="#cb131-255" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>fetal_health_fac <span class="ot">&lt;-</span> <span class="fu">factor</span>(fet_df<span class="sc">$</span>fetal_health, <span class="at">ordered =</span> <span class="cn">TRUE</span>, </span>
<span id="cb131-256"><a href="#cb131-256" aria-hidden="true" tabindex="-1"></a>                                <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"1"</span>, <span class="st">"2"</span>, <span class="st">"3"</span>))</span>
<span id="cb131-257"><a href="#cb131-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-258"><a href="#cb131-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-259"><a href="#cb131-259" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking classes of new columns</span></span>
<span id="cb131-260"><a href="#cb131-260" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(fet_df<span class="sc">$</span>fetal_health_fac)</span>
<span id="cb131-261"><a href="#cb131-261" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(fet_df<span class="sc">$</span>fetal_health)</span>
<span id="cb131-262"><a href="#cb131-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-263"><a href="#cb131-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-264"><a href="#cb131-264" aria-hidden="true" tabindex="-1"></a><span class="fu">## Splitting the Data</span></span>
<span id="cb131-265"><a href="#cb131-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-266"><a href="#cb131-266" aria-hidden="true" tabindex="-1"></a>I am setting aside the test (hold-out) set for use after cross-validation/ hyperparameter optimization. The training set has 1488 observations (70% of the data) and the test set has 638 observations (30% of the data).</span>
<span id="cb131-267"><a href="#cb131-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-270"><a href="#cb131-270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb131-271"><a href="#cb131-271" aria-hidden="true" tabindex="-1"></a><span class="co">#create ID column</span></span>
<span id="cb131-272"><a href="#cb131-272" aria-hidden="true" tabindex="-1"></a>fet_df<span class="sc">$</span>id<span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(fet_df)</span>
<span id="cb131-273"><a href="#cb131-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-274"><a href="#cb131-274" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12</span>)</span>
<span id="cb131-275"><a href="#cb131-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-276"><a href="#cb131-276" aria-hidden="true" tabindex="-1"></a><span class="co">#use 70% of dataset as training set and 30% as test set </span></span>
<span id="cb131-277"><a href="#cb131-277" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> fet_df <span class="sc">%&gt;%</span> <span class="fu">sample_frac</span>(<span class="fl">0.7</span>) </span>
<span id="cb131-278"><a href="#cb131-278" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> <span class="fu">anti_join</span>(fet_df, train, <span class="at">by =</span> <span class="st">'id'</span>)</span>
<span id="cb131-279"><a href="#cb131-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-280"><a href="#cb131-280" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking dimensions of split data</span></span>
<span id="cb131-281"><a href="#cb131-281" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train)</span>
<span id="cb131-282"><a href="#cb131-282" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span>
<span id="cb131-283"><a href="#cb131-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-284"><a href="#cb131-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-285"><a href="#cb131-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-286"><a href="#cb131-286" aria-hidden="true" tabindex="-1"></a>The rest of the data preprocessing (scaling and outlier imputing) will be done within each cross-validation split using sci-kit learn's pipeline.</span>
<span id="cb131-287"><a href="#cb131-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-288"><a href="#cb131-288" aria-hidden="true" tabindex="-1"></a><span class="fu"># Evaluation Metric</span></span>
<span id="cb131-289"><a href="#cb131-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-290"><a href="#cb131-290" aria-hidden="true" tabindex="-1"></a>A metric that places importance on the detection of categories "suspect" (2) and "pathological" (3) is going to be very important so more caution and attention will be paid to these higher-risk cases. In other words, false negatives are likely to be more harmful than false positives. For instance, we can get very good accuracy score if we are very successful in classifying normal cases but less successful in detecting pathological and suspect cases.</span>
<span id="cb131-291"><a href="#cb131-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-292"><a href="#cb131-292" aria-hidden="true" tabindex="-1"></a>In addition to macro f1 score, I will consider by-class f1 scores to ensure the model is performing sufficiently on suspect and pathological cases.</span>
<span id="cb131-293"><a href="#cb131-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-294"><a href="#cb131-294" aria-hidden="true" tabindex="-1"></a><span class="fu"># Fit Models</span></span>
<span id="cb131-295"><a href="#cb131-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-296"><a href="#cb131-296" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python Set-Up</span></span>
<span id="cb131-297"><a href="#cb131-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-300"><a href="#cb131-300" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-301"><a href="#cb131-301" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb131-302"><a href="#cb131-302" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb131-303"><a href="#cb131-303" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn <span class="im">as</span> sklearn</span>
<span id="cb131-304"><a href="#cb131-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-305"><a href="#cb131-305" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> linear_model</span>
<span id="cb131-306"><a href="#cb131-306" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb131-307"><a href="#cb131-307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-308"><a href="#cb131-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-311"><a href="#cb131-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-312"><a href="#cb131-312" aria-hidden="true" tabindex="-1"></a><span class="co">#Opening R objects with reticulate/Python</span></span>
<span id="cb131-313"><a href="#cb131-313" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>r.train</span>
<span id="cb131-314"><a href="#cb131-314" aria-hidden="true" tabindex="-1"></a>test<span class="op">=</span>r.test</span>
<span id="cb131-315"><a href="#cb131-315" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb131-316"><a href="#cb131-316" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking class of outcome variable</span></span>
<span id="cb131-317"><a href="#cb131-317" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health'</span>]</span>
<span id="cb131-318"><a href="#cb131-318" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health_fac'</span>]</span>
<span id="cb131-319"><a href="#cb131-319" aria-hidden="true" tabindex="-1"></a>train.dtypes[<span class="st">'fetal_health_bin'</span>]</span>
<span id="cb131-320"><a href="#cb131-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-321"><a href="#cb131-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-322"><a href="#cb131-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-325"><a href="#cb131-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-326"><a href="#cb131-326" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting subsets for x and y variables</span></span>
<span id="cb131-327"><a href="#cb131-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-328"><a href="#cb131-328" aria-hidden="true" tabindex="-1"></a>train_x<span class="op">=</span>train[[<span class="st">'baseline.value'</span>,</span>
<span id="cb131-329"><a href="#cb131-329" aria-hidden="true" tabindex="-1"></a><span class="st">'accelerations'</span>,</span>
<span id="cb131-330"><a href="#cb131-330" aria-hidden="true" tabindex="-1"></a><span class="st">'fetal_movement'</span>,</span>
<span id="cb131-331"><a href="#cb131-331" aria-hidden="true" tabindex="-1"></a><span class="st">'uterine_contractions'</span>,</span>
<span id="cb131-332"><a href="#cb131-332" aria-hidden="true" tabindex="-1"></a><span class="st">'light_decelerations'</span>,</span>
<span id="cb131-333"><a href="#cb131-333" aria-hidden="true" tabindex="-1"></a><span class="st">'severe_decelerations'</span>,</span>
<span id="cb131-334"><a href="#cb131-334" aria-hidden="true" tabindex="-1"></a><span class="st">'prolongued_decelerations'</span>,</span>
<span id="cb131-335"><a href="#cb131-335" aria-hidden="true" tabindex="-1"></a><span class="st">'abnormal_short_term_variability'</span>,</span>
<span id="cb131-336"><a href="#cb131-336" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_short_term_variability'</span>,</span>
<span id="cb131-337"><a href="#cb131-337" aria-hidden="true" tabindex="-1"></a><span class="st">'percentage_of_time_with_abnormal_long_term_variability'</span>,</span>
<span id="cb131-338"><a href="#cb131-338" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_long_term_variability'</span>,</span>
<span id="cb131-339"><a href="#cb131-339" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_width'</span>,</span>
<span id="cb131-340"><a href="#cb131-340" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_min'</span>,</span>
<span id="cb131-341"><a href="#cb131-341" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_max'</span>,</span>
<span id="cb131-342"><a href="#cb131-342" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_peaks'</span>,</span>
<span id="cb131-343"><a href="#cb131-343" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_zeroes'</span>,</span>
<span id="cb131-344"><a href="#cb131-344" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mode'</span>,</span>
<span id="cb131-345"><a href="#cb131-345" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mean'</span>,</span>
<span id="cb131-346"><a href="#cb131-346" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_median'</span>,</span>
<span id="cb131-347"><a href="#cb131-347" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_variance'</span>,</span>
<span id="cb131-348"><a href="#cb131-348" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_negative'</span>,</span>
<span id="cb131-349"><a href="#cb131-349" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_zero'</span>,</span>
<span id="cb131-350"><a href="#cb131-350" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_positive'</span>]]</span>
<span id="cb131-351"><a href="#cb131-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-352"><a href="#cb131-352" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for 3 Classes</span></span>
<span id="cb131-353"><a href="#cb131-353" aria-hidden="true" tabindex="-1"></a>train_y<span class="op">=</span>train[[<span class="st">'fetal_health'</span>]]</span>
<span id="cb131-354"><a href="#cb131-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-355"><a href="#cb131-355" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Ordered 3 Classes</span></span>
<span id="cb131-356"><a href="#cb131-356" aria-hidden="true" tabindex="-1"></a>train_y_fac<span class="op">=</span>train[[<span class="st">'fetal_health_fac'</span>]]</span>
<span id="cb131-357"><a href="#cb131-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-358"><a href="#cb131-358" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Binary</span></span>
<span id="cb131-359"><a href="#cb131-359" aria-hidden="true" tabindex="-1"></a>train_y_bin<span class="op">=</span>train[[<span class="st">'fetal_health_bin'</span>]]</span>
<span id="cb131-360"><a href="#cb131-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-361"><a href="#cb131-361" aria-hidden="true" tabindex="-1"></a><span class="co">#convert data type from matrix to numpy ndarray</span></span>
<span id="cb131-362"><a href="#cb131-362" aria-hidden="true" tabindex="-1"></a>train_y<span class="op">=</span>train_y.values.ravel()</span>
<span id="cb131-363"><a href="#cb131-363" aria-hidden="true" tabindex="-1"></a>train_y_fac<span class="op">=</span>train_y_fac.values.ravel()</span>
<span id="cb131-364"><a href="#cb131-364" aria-hidden="true" tabindex="-1"></a>train_y_bin<span class="op">=</span>train_y_bin.values.ravel()</span>
<span id="cb131-365"><a href="#cb131-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-366"><a href="#cb131-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-367"><a href="#cb131-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-368"><a href="#cb131-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### Defining a Function to Remove Outliers Based on Z-score</span></span>
<span id="cb131-369"><a href="#cb131-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-370"><a href="#cb131-370" aria-hidden="true" tabindex="-1"></a>I used ChatGPT to help with this code. I still need to learn more about working with Numpy arrays and Pandas data frames but this eventually helped me figure out a function that could be implemented with Scikit-learn's pipeline.</span>
<span id="cb131-371"><a href="#cb131-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-374"><a href="#cb131-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-375"><a href="#cb131-375" aria-hidden="true" tabindex="-1"></a><span class="co">#changing class of data frame to work with Function Transformer</span></span>
<span id="cb131-376"><a href="#cb131-376" aria-hidden="true" tabindex="-1"></a>np.array(train) </span>
<span id="cb131-377"><a href="#cb131-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-378"><a href="#cb131-378" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb131-379"><a href="#cb131-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-380"><a href="#cb131-380" aria-hidden="true" tabindex="-1"></a><span class="co">#This code (from ChatGPT) transforms a function to work within Pipeline</span></span>
<span id="cb131-381"><a href="#cb131-381" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ElementWiseFunctionTransformer(BaseEstimator, TransformerMixin):</span>
<span id="cb131-382"><a href="#cb131-382" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, func):</span>
<span id="cb131-383"><a href="#cb131-383" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.func <span class="op">=</span> func</span>
<span id="cb131-384"><a href="#cb131-384" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb131-385"><a href="#cb131-385" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb131-386"><a href="#cb131-386" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb131-387"><a href="#cb131-387" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb131-388"><a href="#cb131-388" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X):</span>
<span id="cb131-389"><a href="#cb131-389" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.func(X)</span>
<span id="cb131-390"><a href="#cb131-390" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb131-391"><a href="#cb131-391" aria-hidden="true" tabindex="-1"></a><span class="co">#Defining a function that replaces standardized observations with a z-score greater than the absolute value of 3 with 0 (mean). Observations will be standardized in the previous step in the pipe</span></span>
<span id="cb131-392"><a href="#cb131-392" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace_greater_than_abs_three(arr):</span>
<span id="cb131-393"><a href="#cb131-393" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.where(np.<span class="bu">abs</span>(arr) <span class="op">&gt;</span> <span class="dv">3</span>, <span class="dv">0</span>, arr)</span>
<span id="cb131-394"><a href="#cb131-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-395"><a href="#cb131-395" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-396"><a href="#cb131-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-397"><a href="#cb131-397" aria-hidden="true" tabindex="-1"></a><span class="fu">## Penalized Logistic Regression</span></span>
<span id="cb131-398"><a href="#cb131-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-401"><a href="#cb131-401" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-402"><a href="#cb131-402" aria-hidden="true" tabindex="-1"></a><span class="co">#import python modules</span></span>
<span id="cb131-403"><a href="#cb131-403" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb131-404"><a href="#cb131-404" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb131-405"><a href="#cb131-405" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb131-406"><a href="#cb131-406" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb131-407"><a href="#cb131-407" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb131-408"><a href="#cb131-408" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb131-409"><a href="#cb131-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-410"><a href="#cb131-410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-411"><a href="#cb131-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-412"><a href="#cb131-412" aria-hidden="true" tabindex="-1"></a><span class="fu">### Testing l1 and l2 Penalty</span></span>
<span id="cb131-413"><a href="#cb131-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-416"><a href="#cb131-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-417"><a href="#cb131-417" aria-hidden="true" tabindex="-1"></a><span class="co">#setting parameters to be tested with GridSearchCV</span></span>
<span id="cb131-418"><a href="#cb131-418" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb131-419"><a href="#cb131-419" aria-hidden="true" tabindex="-1"></a>{<span class="st">'log_l__C'</span>: [<span class="fl">0.01</span>,<span class="fl">0.1</span>,<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>],</span>
<span id="cb131-420"><a href="#cb131-420" aria-hidden="true" tabindex="-1"></a><span class="st">'log_l__penalty'</span>: [<span class="st">'l1'</span>, <span class="st">'l2'</span>]} <span class="co"># testing l1 and l2 penalty</span></span>
<span id="cb131-421"><a href="#cb131-421" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb131-422"><a href="#cb131-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-423"><a href="#cb131-423" aria-hidden="true" tabindex="-1"></a><span class="co">#define pipeline</span></span>
<span id="cb131-424"><a href="#cb131-424" aria-hidden="true" tabindex="-1"></a>log_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'log_l'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>))])</span>
<span id="cb131-425"><a href="#cb131-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-426"><a href="#cb131-426" aria-hidden="true" tabindex="-1"></a><span class="co">#define pipeline that also removes outliers</span></span>
<span id="cb131-427"><a href="#cb131-427" aria-hidden="true" tabindex="-1"></a>log_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'log_l'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>))])</span>
<span id="cb131-428"><a href="#cb131-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-429"><a href="#cb131-429" aria-hidden="true" tabindex="-1"></a><span class="co">#Apply Grid Search</span></span>
<span id="cb131-430"><a href="#cb131-430" aria-hidden="true" tabindex="-1"></a>GS_log <span class="op">=</span> GridSearchCV(log_pipe, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#with outliers</span></span>
<span id="cb131-431"><a href="#cb131-431" aria-hidden="true" tabindex="-1"></a>GS_log_no_out <span class="op">=</span> GridSearchCV(log_pipe_no_out, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#with outliers imputed</span></span>
<span id="cb131-432"><a href="#cb131-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-433"><a href="#cb131-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-434"><a href="#cb131-434" aria-hidden="true" tabindex="-1"></a>Using the pipeline should apply transformations at each fold to avoid data leakage and get more accurate evaluation metrics.</span>
<span id="cb131-435"><a href="#cb131-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-436"><a href="#cb131-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Defining a Function to Return Macro f1 Scores and By-Class F1 Scores</span></span>
<span id="cb131-437"><a href="#cb131-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-438"><a href="#cb131-438" aria-hidden="true" tabindex="-1"></a>Below I define a function that takes in the outcome variable (y) and pre-defined GridSearchCV object and outputs macro f1 and by-class f1 scores</span>
<span id="cb131-439"><a href="#cb131-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-442"><a href="#cb131-442" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-443"><a href="#cb131-443" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> CV_F1_function(GS_object, outcome):</span>
<span id="cb131-444"><a href="#cb131-444" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb131-445"><a href="#cb131-445" aria-hidden="true" tabindex="-1"></a>  random.seed(<span class="dv">3</span>) <span class="co"># set seed each time the algorithm is run for reproducibility</span></span>
<span id="cb131-446"><a href="#cb131-446" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb131-447"><a href="#cb131-447" aria-hidden="true" tabindex="-1"></a>  <span class="co">#print best parameters and macro f1</span></span>
<span id="cb131-448"><a href="#cb131-448" aria-hidden="true" tabindex="-1"></a>  best_GS<span class="op">=</span>GS_object.fit(train_x, outcome) <span class="co">#finds the best parameters</span></span>
<span id="cb131-449"><a href="#cb131-449" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(best_GS.best_params_)</span>
<span id="cb131-450"><a href="#cb131-450" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Best Macro F1:  </span><span class="sc">{</span>best_GS<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb131-451"><a href="#cb131-451" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb131-452"><a href="#cb131-452" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Print by-class f1 scores </span></span>
<span id="cb131-453"><a href="#cb131-453" aria-hidden="true" tabindex="-1"></a>  pred1 <span class="op">=</span> cross_val_predict(best_GS.best_estimator_, train_x, outcome, cv<span class="op">=</span><span class="dv">5</span>) <span class="co">#plugs in best parameters</span></span>
<span id="cb131-454"><a href="#cb131-454" aria-hidden="true" tabindex="-1"></a>  f1_class <span class="op">=</span> f1_score(outcome, pred1, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculates by-class f1 scores</span></span>
<span id="cb131-455"><a href="#cb131-455" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(f1_class)</span>
<span id="cb131-456"><a href="#cb131-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-457"><a href="#cb131-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-458"><a href="#cb131-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-459"><a href="#cb131-459" aria-hidden="true" tabindex="-1"></a>I use the above function to determine best parameters and optimize macro f1 scores for our data with outliers and with the outliers removed and imputed with the mean (0). This function returns optimized parameters, macro f1 scores, and by-class f1 scores (in the order: normal, suspect, pathological). I use this function throughout the rest of this document.</span>
<span id="cb131-460"><a href="#cb131-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-461"><a href="#cb131-461" aria-hidden="true" tabindex="-1"></a>Plugging logistic regression grid search objects into function:</span>
<span id="cb131-462"><a href="#cb131-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-465"><a href="#cb131-465" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-466"><a href="#cb131-466" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span>
<span id="cb131-467"><a href="#cb131-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-468"><a href="#cb131-468" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_no_out, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes with x variable outliers removed</span></span>
<span id="cb131-469"><a href="#cb131-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-470"><a href="#cb131-470" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span>
<span id="cb131-471"><a href="#cb131-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-472"><a href="#cb131-472" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome with x variable outliers removed</span></span>
<span id="cb131-473"><a href="#cb131-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-474"><a href="#cb131-474" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-475"><a href="#cb131-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-476"><a href="#cb131-476" aria-hidden="true" tabindex="-1"></a>Our best macro f1 score for the 3 class unordered outcome (outliers kept) is 0.8194 where the f1 for "normal" is 0.952, 0.7095 for "suspect", and 0.8 for "pathological". The optimized parameters are an l1 penalty and C=1 (C is 1/lambda, so a small C indicates a large penalty).</span>
<span id="cb131-477"><a href="#cb131-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-478"><a href="#cb131-478" aria-hidden="true" tabindex="-1"></a>For the binary outcome, out best f1 score is 0.8585 (occurs when outliers are kept) with an f1 for normal of 0.9416 and for the suspect/pathological cases 0.7752. The optimized C is 100, (a smaller penalty than for the 3 class outcome) and once again, the l1 penalty.</span>
<span id="cb131-479"><a href="#cb131-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-480"><a href="#cb131-480" aria-hidden="true" tabindex="-1"></a><span class="fu">## Elastic Net Regularization</span></span>
<span id="cb131-481"><a href="#cb131-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-484"><a href="#cb131-484" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-485"><a href="#cb131-485" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb131-486"><a href="#cb131-486" aria-hidden="true" tabindex="-1"></a>{<span class="st">'log_net__l1_ratio'</span>: [<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="dv">1</span>], <span class="co">#1 indicates full f1 penalty </span></span>
<span id="cb131-487"><a href="#cb131-487" aria-hidden="true" tabindex="-1"></a><span class="st">'log_net__C'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="dv">10</span>, <span class="dv">100</span>]} <span class="co"># tests 20 values of C between 0 and 4 on the log scale}</span></span>
<span id="cb131-488"><a href="#cb131-488" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb131-489"><a href="#cb131-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-490"><a href="#cb131-490" aria-hidden="true" tabindex="-1"></a>log_net <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>)</span>
<span id="cb131-491"><a href="#cb131-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-492"><a href="#cb131-492" aria-hidden="true" tabindex="-1"></a>log_net_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'log_net'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>))])</span>
<span id="cb131-493"><a href="#cb131-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-494"><a href="#cb131-494" aria-hidden="true" tabindex="-1"></a>log_net_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'log_net'</span>, LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, penalty<span class="op">=</span><span class="st">'elasticnet'</span>))])</span>
<span id="cb131-495"><a href="#cb131-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-496"><a href="#cb131-496" aria-hidden="true" tabindex="-1"></a>GS_log_net <span class="op">=</span> GridSearchCV(log_net_pipe, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-497"><a href="#cb131-497" aria-hidden="true" tabindex="-1"></a>GS_log_net_no_out <span class="op">=</span> GridSearchCV(log_net_pipe_no_out, param_grid<span class="op">=</span>params, scoring<span class="op">=</span><span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-498"><a href="#cb131-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-499"><a href="#cb131-499" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-500"><a href="#cb131-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-503"><a href="#cb131-503" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-504"><a href="#cb131-504" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span>
<span id="cb131-505"><a href="#cb131-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-506"><a href="#cb131-506" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers removed</span></span>
<span id="cb131-507"><a href="#cb131-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-508"><a href="#cb131-508" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span>
<span id="cb131-509"><a href="#cb131-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-510"><a href="#cb131-510" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_log_net_no_out, outcome<span class="op">=</span>train_y_bin)<span class="co">#Outliers Removed</span></span>
<span id="cb131-511"><a href="#cb131-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-512"><a href="#cb131-512" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-513"><a href="#cb131-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-514"><a href="#cb131-514" aria-hidden="true" tabindex="-1"></a>Again, our best macro f1 score for the unordered 3 class outcome (outliers kept) is 0.8194. The optimized C is still 1, and the l1 ratio is 0.9, indicating a stronger l1 penalty performs better. This is consistent with the previous runs finding the l1 penalty outperformed the l2 penalty. For the binary outcome, the macro f1 score is 0.8589. This is very close to the results from the previous section. For simplicity's sake I will only test the optimized parameters with the l1 penalty from the previous section on the final test set.</span>
<span id="cb131-515"><a href="#cb131-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-516"><a href="#cb131-516" aria-hidden="true" tabindex="-1"></a><span class="fu">## Boosting</span></span>
<span id="cb131-517"><a href="#cb131-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-520"><a href="#cb131-520" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-521"><a href="#cb131-521" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb131-522"><a href="#cb131-522" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)</span>
<span id="cb131-523"><a href="#cb131-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-524"><a href="#cb131-524" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb131-525"><a href="#cb131-525" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb131-526"><a href="#cb131-526" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb131-527"><a href="#cb131-527" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb131-528"><a href="#cb131-528" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> FunctionTransformer</span>
<span id="cb131-529"><a href="#cb131-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-530"><a href="#cb131-530" aria-hidden="true" tabindex="-1"></a><span class="co">#While it is unnecessary to scale data for boosting, I include it so we can use it to remove outliers in the next pipeline. Scaling the data should not affect model performance.</span></span>
<span id="cb131-531"><a href="#cb131-531" aria-hidden="true" tabindex="-1"></a>xgb_pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'multi:softprob'</span>))]) <span class="co">#multi::softporb is used for multiclass outcome variables</span></span>
<span id="cb131-532"><a href="#cb131-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-533"><a href="#cb131-533" aria-hidden="true" tabindex="-1"></a>xgb_pipe_no_out <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span> <span class="st">'multi:softprob'</span>))]) </span>
<span id="cb131-534"><a href="#cb131-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-535"><a href="#cb131-535" aria-hidden="true" tabindex="-1"></a>xgb_pipe_bin <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'binary:logistic'</span>))]) <span class="co">#binary:logisitic is used for binary outcome variables</span></span>
<span id="cb131-536"><a href="#cb131-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-537"><a href="#cb131-537" aria-hidden="true" tabindex="-1"></a>xgb_pipe_no_out_bin <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'xgb'</span>, xgb.XGBClassifier(objective<span class="op">=</span> <span class="st">'binary:logistic'</span>))]) </span>
<span id="cb131-538"><a href="#cb131-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-539"><a href="#cb131-539" aria-hidden="true" tabindex="-1"></a><span class="co">#setting parameters to grid search</span></span>
<span id="cb131-540"><a href="#cb131-540" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb131-541"><a href="#cb131-541" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__n_estimators"</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">1000</span>], <span class="co">#while more trees could increase performance slightly for some models, this is too time consuming to run</span></span>
<span id="cb131-542"><a href="#cb131-542" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__learning_rate"</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>],</span>
<span id="cb131-543"><a href="#cb131-543" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgb__max_depth"</span>: [<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>] <span class="co">#max depth of a tree... I tried to tune to higher depths however this was very time consuming to run and didn't provide much in return/ could possibly lead to overfitting</span></span>
<span id="cb131-544"><a href="#cb131-544" aria-hidden="true" tabindex="-1"></a>}<span class="co">#setting parameters to grid search</span></span>
<span id="cb131-545"><a href="#cb131-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-546"><a href="#cb131-546" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class outcome labels (0,1,2, work with xgboost as opposed to 1,2,3)</span></span>
<span id="cb131-547"><a href="#cb131-547" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb131-548"><a href="#cb131-548" aria-hidden="true" tabindex="-1"></a>train_yb <span class="op">=</span> le.fit_transform(train_y)</span>
<span id="cb131-549"><a href="#cb131-549" aria-hidden="true" tabindex="-1"></a>train_yb_fac <span class="op">=</span> le.fit_transform(train_y_fac)</span>
<span id="cb131-550"><a href="#cb131-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-551"><a href="#cb131-551" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class of binary outcome to work with xgboost</span></span>
<span id="cb131-552"><a href="#cb131-552" aria-hidden="true" tabindex="-1"></a>train_yb_bin <span class="op">=</span> le.fit_transform(train_y_bin)</span>
<span id="cb131-553"><a href="#cb131-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-554"><a href="#cb131-554" aria-hidden="true" tabindex="-1"></a><span class="co">#Implementing grid search with cross validation</span></span>
<span id="cb131-555"><a href="#cb131-555" aria-hidden="true" tabindex="-1"></a>GS_xgb<span class="op">=</span> GridSearchCV(xgb_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb131-556"><a href="#cb131-556" aria-hidden="true" tabindex="-1"></a>GS_xgb_no_out<span class="op">=</span> GridSearchCV(xgb_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb131-557"><a href="#cb131-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-558"><a href="#cb131-558" aria-hidden="true" tabindex="-1"></a>GS_xgb_bin<span class="op">=</span> GridSearchCV(xgb_pipe_bin, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb131-559"><a href="#cb131-559" aria-hidden="true" tabindex="-1"></a>GS_xgb_no_out_bin<span class="op">=</span> GridSearchCV(xgb_pipe_no_out_bin, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb131-560"><a href="#cb131-560" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-561"><a href="#cb131-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-564"><a href="#cb131-564" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-565"><a href="#cb131-565" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb, outcome<span class="op">=</span>train_yb) <span class="co">#3 Classes</span></span>
<span id="cb131-566"><a href="#cb131-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-567"><a href="#cb131-567" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_no_out, outcome<span class="op">=</span>train_yb) <span class="co">#Outliers Removed</span></span>
<span id="cb131-568"><a href="#cb131-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-569"><a href="#cb131-569" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_bin, outcome<span class="op">=</span>train_yb_bin) <span class="co">#Binary Outcome</span></span>
<span id="cb131-570"><a href="#cb131-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-571"><a href="#cb131-571" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_xgb_no_out_bin, outcome<span class="op">=</span>train_yb_bin) <span class="co">#Outliers Removed</span></span>
<span id="cb131-572"><a href="#cb131-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-573"><a href="#cb131-573" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-574"><a href="#cb131-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-575"><a href="#cb131-575" aria-hidden="true" tabindex="-1"></a>These are the best performing models so far. The model with the binary outcome class (with outliers removed) performs fairly well on the suspect/pathological outcome class (macro f1= 0.935, f1 for "normal"=0.972, and f1 for "suspect/pathological"=0.898).</span>
<span id="cb131-576"><a href="#cb131-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-577"><a href="#cb131-577" aria-hidden="true" tabindex="-1"></a><span class="fu">## Support Vector Machines (SVM)</span></span>
<span id="cb131-578"><a href="#cb131-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-581"><a href="#cb131-581" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-582"><a href="#cb131-582" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb131-583"><a href="#cb131-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-584"><a href="#cb131-584" aria-hidden="true" tabindex="-1"></a>params<span class="op">=</span> {</span>
<span id="cb131-585"><a href="#cb131-585" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__C'</span>: [<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">200</span>], <span class="co">#misclassification error term</span></span>
<span id="cb131-586"><a href="#cb131-586" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__gamma'</span>: [<span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>, <span class="fl">0.001</span>], <span class="co">#distance of points to decision boundary being considered</span></span>
<span id="cb131-587"><a href="#cb131-587" aria-hidden="true" tabindex="-1"></a>  <span class="st">'svm__kernel'</span>: [<span class="st">'rbf'</span>, <span class="st">'poly'</span>, <span class="st">'sigmoid'</span>, <span class="st">'linear'</span>]</span>
<span id="cb131-588"><a href="#cb131-588" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb131-589"><a href="#cb131-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-590"><a href="#cb131-590" aria-hidden="true" tabindex="-1"></a>svm_cl_pipe <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'svm'</span>, svm.SVC())])</span>
<span id="cb131-591"><a href="#cb131-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-592"><a href="#cb131-592" aria-hidden="true" tabindex="-1"></a>svm_cl_pipe_no_out <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'svm'</span>, svm.SVC())])</span>
<span id="cb131-593"><a href="#cb131-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-594"><a href="#cb131-594" aria-hidden="true" tabindex="-1"></a>GS_svm<span class="op">=</span> GridSearchCV(svm_cl_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-595"><a href="#cb131-595" aria-hidden="true" tabindex="-1"></a>GS_svm_no_out<span class="op">=</span> GridSearchCV(svm_cl_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-596"><a href="#cb131-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-597"><a href="#cb131-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-598"><a href="#cb131-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-601"><a href="#cb131-601" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-602"><a href="#cb131-602" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm, outcome<span class="op">=</span>train_y) <span class="co">#Unordered 3 Classes</span></span>
<span id="cb131-603"><a href="#cb131-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-604"><a href="#cb131-604" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers Removed</span></span>
<span id="cb131-605"><a href="#cb131-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-606"><a href="#cb131-606" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span>
<span id="cb131-607"><a href="#cb131-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-608"><a href="#cb131-608" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_svm_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Outliers Removed</span></span>
<span id="cb131-609"><a href="#cb131-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-610"><a href="#cb131-610" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-611"><a href="#cb131-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-612"><a href="#cb131-612" aria-hidden="true" tabindex="-1"></a>Again the 3 class model has trouble detecting suspect cases, so in this case, I might prefer the binary outcome model (where suspect and pathological classes combined f1 score is 0.8489.) Boosting still performs better for both the three class and binary outcome variables.</span>
<span id="cb131-613"><a href="#cb131-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-614"><a href="#cb131-614" aria-hidden="true" tabindex="-1"></a><span class="fu">## K-Nearest Neighbors (KNN)</span></span>
<span id="cb131-615"><a href="#cb131-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-616"><a href="#cb131-616" aria-hidden="true" tabindex="-1"></a>Finally I tested K nearest neighbors to see if a high variance model (low bias) may perform better than boosting. This is not the case.</span>
<span id="cb131-617"><a href="#cb131-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-620"><a href="#cb131-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-621"><a href="#cb131-621" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb131-622"><a href="#cb131-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-623"><a href="#cb131-623" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">'knn__n_neighbors'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>]}</span>
<span id="cb131-624"><a href="#cb131-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-625"><a href="#cb131-625" aria-hidden="true" tabindex="-1"></a>knn_pipe <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'knn'</span>, KNeighborsClassifier())])</span>
<span id="cb131-626"><a href="#cb131-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-627"><a href="#cb131-627" aria-hidden="true" tabindex="-1"></a>knn_pipe_no_out <span class="op">=</span> Pipeline([(<span class="st">'scale'</span>, StandardScaler()), (<span class="st">'elementwise_function'</span>, ElementWiseFunctionTransformer(replace_greater_than_abs_three)), (<span class="st">'knn'</span>, KNeighborsClassifier())])</span>
<span id="cb131-628"><a href="#cb131-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-629"><a href="#cb131-629" aria-hidden="true" tabindex="-1"></a>GS_knn<span class="op">=</span> GridSearchCV(knn_pipe, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-630"><a href="#cb131-630" aria-hidden="true" tabindex="-1"></a>GS_knn_no_out<span class="op">=</span> GridSearchCV(knn_pipe_no_out, param_grid<span class="op">=</span>params, scoring <span class="op">=</span> <span class="st">"f1_macro"</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb131-631"><a href="#cb131-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-632"><a href="#cb131-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-633"><a href="#cb131-633" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-634"><a href="#cb131-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-637"><a href="#cb131-637" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-638"><a href="#cb131-638" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn, outcome<span class="op">=</span>train_y) <span class="co">#3 Classes</span></span>
<span id="cb131-639"><a href="#cb131-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-640"><a href="#cb131-640" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn_no_out, outcome<span class="op">=</span>train_y) <span class="co">#Outliers Removed</span></span>
<span id="cb131-641"><a href="#cb131-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-642"><a href="#cb131-642" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn, outcome<span class="op">=</span>train_y_bin) <span class="co">#Binary Outcome</span></span>
<span id="cb131-643"><a href="#cb131-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-644"><a href="#cb131-644" aria-hidden="true" tabindex="-1"></a>CV_F1_function(GS_object<span class="op">=</span>GS_knn_no_out, outcome<span class="op">=</span>train_y_bin) <span class="co">#Outliers Removed</span></span>
<span id="cb131-645"><a href="#cb131-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-646"><a href="#cb131-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-647"><a href="#cb131-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-648"><a href="#cb131-648" aria-hidden="true" tabindex="-1"></a><span class="fu">## Final Model Evaluation</span></span>
<span id="cb131-649"><a href="#cb131-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-650"><a href="#cb131-650" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test set pre-processing</span></span>
<span id="cb131-651"><a href="#cb131-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-654"><a href="#cb131-654" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-655"><a href="#cb131-655" aria-hidden="true" tabindex="-1"></a><span class="co">#Test set pre-processing</span></span>
<span id="cb131-656"><a href="#cb131-656" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting subsets for x and y variables</span></span>
<span id="cb131-657"><a href="#cb131-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-658"><a href="#cb131-658" aria-hidden="true" tabindex="-1"></a>test_x<span class="op">=</span>test[[<span class="st">'baseline.value'</span>,</span>
<span id="cb131-659"><a href="#cb131-659" aria-hidden="true" tabindex="-1"></a><span class="st">'accelerations'</span>,</span>
<span id="cb131-660"><a href="#cb131-660" aria-hidden="true" tabindex="-1"></a><span class="st">'fetal_movement'</span>,</span>
<span id="cb131-661"><a href="#cb131-661" aria-hidden="true" tabindex="-1"></a><span class="st">'uterine_contractions'</span>,</span>
<span id="cb131-662"><a href="#cb131-662" aria-hidden="true" tabindex="-1"></a><span class="st">'light_decelerations'</span>,</span>
<span id="cb131-663"><a href="#cb131-663" aria-hidden="true" tabindex="-1"></a><span class="st">'severe_decelerations'</span>,</span>
<span id="cb131-664"><a href="#cb131-664" aria-hidden="true" tabindex="-1"></a><span class="st">'prolongued_decelerations'</span>,</span>
<span id="cb131-665"><a href="#cb131-665" aria-hidden="true" tabindex="-1"></a><span class="st">'abnormal_short_term_variability'</span>,</span>
<span id="cb131-666"><a href="#cb131-666" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_short_term_variability'</span>,</span>
<span id="cb131-667"><a href="#cb131-667" aria-hidden="true" tabindex="-1"></a><span class="st">'percentage_of_time_with_abnormal_long_term_variability'</span>,</span>
<span id="cb131-668"><a href="#cb131-668" aria-hidden="true" tabindex="-1"></a><span class="st">'mean_value_of_long_term_variability'</span>,</span>
<span id="cb131-669"><a href="#cb131-669" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_width'</span>,</span>
<span id="cb131-670"><a href="#cb131-670" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_min'</span>,</span>
<span id="cb131-671"><a href="#cb131-671" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_max'</span>,</span>
<span id="cb131-672"><a href="#cb131-672" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_peaks'</span>,</span>
<span id="cb131-673"><a href="#cb131-673" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_number_of_zeroes'</span>,</span>
<span id="cb131-674"><a href="#cb131-674" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mode'</span>,</span>
<span id="cb131-675"><a href="#cb131-675" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_mean'</span>,</span>
<span id="cb131-676"><a href="#cb131-676" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_median'</span>,</span>
<span id="cb131-677"><a href="#cb131-677" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_variance'</span>,</span>
<span id="cb131-678"><a href="#cb131-678" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_negative'</span>,</span>
<span id="cb131-679"><a href="#cb131-679" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_zero'</span>,</span>
<span id="cb131-680"><a href="#cb131-680" aria-hidden="true" tabindex="-1"></a><span class="st">'histogram_tendency_positive'</span>]]</span>
<span id="cb131-681"><a href="#cb131-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-682"><a href="#cb131-682" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for 3 Classes</span></span>
<span id="cb131-683"><a href="#cb131-683" aria-hidden="true" tabindex="-1"></a>test_y<span class="op">=</span>test[[<span class="st">'fetal_health'</span>]]</span>
<span id="cb131-684"><a href="#cb131-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-685"><a href="#cb131-685" aria-hidden="true" tabindex="-1"></a><span class="co">#Outcome Class for Binary</span></span>
<span id="cb131-686"><a href="#cb131-686" aria-hidden="true" tabindex="-1"></a>test_y_bin<span class="op">=</span>test[[<span class="st">'fetal_health_bin'</span>]]</span>
<span id="cb131-687"><a href="#cb131-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-688"><a href="#cb131-688" aria-hidden="true" tabindex="-1"></a><span class="co">#convert data type from matrix to numpy npdarray</span></span>
<span id="cb131-689"><a href="#cb131-689" aria-hidden="true" tabindex="-1"></a>test_y<span class="op">=</span>test_y.values.ravel()</span>
<span id="cb131-690"><a href="#cb131-690" aria-hidden="true" tabindex="-1"></a>test_y_bin<span class="op">=</span>test_y_bin.values.ravel()</span>
<span id="cb131-691"><a href="#cb131-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-692"><a href="#cb131-692" aria-hidden="true" tabindex="-1"></a><span class="co">#Standardize Test Data Based on column means and standard deviations of training set</span></span>
<span id="cb131-693"><a href="#cb131-693" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> (test_x <span class="op">-</span> train_x.mean()) <span class="op">/</span> train_x.std()</span>
<span id="cb131-694"><a href="#cb131-694" aria-hidden="true" tabindex="-1"></a>test_x_no_out<span class="op">=</span>replace_greater_than_abs_three(test_x) <span class="co">#create test df with outliers imputed with the mean (0)</span></span>
<span id="cb131-695"><a href="#cb131-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-696"><a href="#cb131-696" aria-hidden="true" tabindex="-1"></a><span class="co">#For simplicity, all variables (including dummy variables) have been standardized (the pipeline did this as well). While unnecessary, this should not affect results. </span></span>
<span id="cb131-697"><a href="#cb131-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-698"><a href="#cb131-698" aria-hidden="true" tabindex="-1"></a><span class="co">#Standardize full training data</span></span>
<span id="cb131-699"><a href="#cb131-699" aria-hidden="true" tabindex="-1"></a>train_x_st <span class="op">=</span> (train_x <span class="op">-</span> train_x.mean()) <span class="op">/</span> train_x.std()</span>
<span id="cb131-700"><a href="#cb131-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-701"><a href="#cb131-701" aria-hidden="true" tabindex="-1"></a>train_x_st_no_out<span class="op">=</span>replace_greater_than_abs_three(train_x_st) <span class="co">#create training df with outliers imputed with the mean</span></span>
<span id="cb131-702"><a href="#cb131-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-703"><a href="#cb131-703" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-704"><a href="#cb131-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-705"><a href="#cb131-705" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression</span></span>
<span id="cb131-706"><a href="#cb131-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-709"><a href="#cb131-709" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-710"><a href="#cb131-710" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb131-711"><a href="#cb131-711" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Classes, Outliers Kept: l1 penalty with C=1</span></span>
<span id="cb131-712"><a href="#cb131-712" aria-hidden="true" tabindex="-1"></a>log_final_mod<span class="op">=</span>LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, C<span class="op">=</span><span class="fl">1.0</span>, penalty<span class="op">=</span><span class="st">'l1'</span>) <span class="co">#fit model with optimized hyperparameters</span></span>
<span id="cb131-713"><a href="#cb131-713" aria-hidden="true" tabindex="-1"></a>log_final_mod.fit(train_x_st, train_y)</span>
<span id="cb131-714"><a href="#cb131-714" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>log_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-715"><a href="#cb131-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-716"><a href="#cb131-716" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-717"><a href="#cb131-717" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-718"><a href="#cb131-718" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-719"><a href="#cb131-719" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-720"><a href="#cb131-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-721"><a href="#cb131-721" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Kept: l1 penalty and C=500</span></span>
<span id="cb131-722"><a href="#cb131-722" aria-hidden="true" tabindex="-1"></a>log_final_mod_bin<span class="op">=</span>LogisticRegression(solver<span class="op">=</span><span class="st">'saga'</span>, tol<span class="op">=</span><span class="fl">0.006</span>, C<span class="op">=</span><span class="dv">500</span>, penalty<span class="op">=</span><span class="st">'l1'</span>) <span class="co">#fit model with optimized hyperparameters</span></span>
<span id="cb131-723"><a href="#cb131-723" aria-hidden="true" tabindex="-1"></a>log_final_mod.fit(train_x_st, train_y_bin)</span>
<span id="cb131-724"><a href="#cb131-724" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>log_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-725"><a href="#cb131-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-726"><a href="#cb131-726" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-727"><a href="#cb131-727" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-728"><a href="#cb131-728" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-729"><a href="#cb131-729" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-730"><a href="#cb131-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-731"><a href="#cb131-731" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-732"><a href="#cb131-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-733"><a href="#cb131-733" aria-hidden="true" tabindex="-1"></a><span class="fu">### Boosting</span></span>
<span id="cb131-734"><a href="#cb131-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-737"><a href="#cb131-737" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-738"><a href="#cb131-738" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb131-739"><a href="#cb131-739" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class outcome labels (0,1,2, work with xgboost as opposed to 1,2,3)</span></span>
<span id="cb131-740"><a href="#cb131-740" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb131-741"><a href="#cb131-741" aria-hidden="true" tabindex="-1"></a>test_yb <span class="op">=</span> le.fit_transform(test_y)</span>
<span id="cb131-742"><a href="#cb131-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-743"><a href="#cb131-743" aria-hidden="true" tabindex="-1"></a><span class="co">#fixing class of binary outcome to work with xgboost</span></span>
<span id="cb131-744"><a href="#cb131-744" aria-hidden="true" tabindex="-1"></a>test_yb_bin <span class="op">=</span> le.fit_transform(test_y_bin)</span>
<span id="cb131-745"><a href="#cb131-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-746"><a href="#cb131-746" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class, Outliers Kept: learning_rate= 0.5, max_depth= 8, n_estimators= 50</span></span>
<span id="cb131-747"><a href="#cb131-747" aria-hidden="true" tabindex="-1"></a>boosting_final_mod<span class="op">=</span> xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'multi:softprob'</span>, learning_rate<span class="op">=</span> <span class="fl">0.5</span>, max_depth<span class="op">=</span> <span class="dv">8</span>, n_estimators<span class="op">=</span> <span class="dv">50</span>)</span>
<span id="cb131-748"><a href="#cb131-748" aria-hidden="true" tabindex="-1"></a>boosting_final_mod.fit(train_x_st, train_yb)</span>
<span id="cb131-749"><a href="#cb131-749" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>boosting_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-750"><a href="#cb131-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-751"><a href="#cb131-751" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_yb, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-752"><a href="#cb131-752" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-753"><a href="#cb131-753" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_yb, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-754"><a href="#cb131-754" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-755"><a href="#cb131-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-756"><a href="#cb131-756" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Imputed: learning_rate=0.1, max_depth= 6, n_estimators= 1000</span></span>
<span id="cb131-757"><a href="#cb131-757" aria-hidden="true" tabindex="-1"></a>boosting_final_mod_bin<span class="op">=</span> xgb.XGBClassifier(objective<span class="op">=</span><span class="st">'binary:logistic'</span>, learning_rate<span class="op">=</span> <span class="fl">0.1</span>, max_depth<span class="op">=</span> <span class="dv">6</span>, n_estimators<span class="op">=</span> <span class="dv">1000</span>)</span>
<span id="cb131-758"><a href="#cb131-758" aria-hidden="true" tabindex="-1"></a>boosting_final_mod_bin.fit(train_x_st_no_out, train_yb_bin)</span>
<span id="cb131-759"><a href="#cb131-759" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>boosting_final_mod_bin.predict(test_x_no_out) <span class="co">#make predictions on test set</span></span>
<span id="cb131-760"><a href="#cb131-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-761"><a href="#cb131-761" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_yb_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-762"><a href="#cb131-762" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-763"><a href="#cb131-763" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_yb_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-764"><a href="#cb131-764" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-765"><a href="#cb131-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-766"><a href="#cb131-766" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-767"><a href="#cb131-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-768"><a href="#cb131-768" aria-hidden="true" tabindex="-1"></a><span class="fu">### Support Vector Machines</span></span>
<span id="cb131-769"><a href="#cb131-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-772"><a href="#cb131-772" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-773"><a href="#cb131-773" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb131-774"><a href="#cb131-774" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class Outcome, Outliers Kept: C=10, gamma= 0.1, kernel= 'rbf'</span></span>
<span id="cb131-775"><a href="#cb131-775" aria-hidden="true" tabindex="-1"></a>svm_final_mod<span class="op">=</span>svm.SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span> <span class="fl">0.1</span>, kernel<span class="op">=</span> <span class="st">'rbf'</span>)</span>
<span id="cb131-776"><a href="#cb131-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-777"><a href="#cb131-777" aria-hidden="true" tabindex="-1"></a>svm_final_mod.fit(train_x_st, train_y)</span>
<span id="cb131-778"><a href="#cb131-778" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>svm_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-779"><a href="#cb131-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-780"><a href="#cb131-780" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-781"><a href="#cb131-781" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-782"><a href="#cb131-782" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-783"><a href="#cb131-783" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-784"><a href="#cb131-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-785"><a href="#cb131-785" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome Outliers Kept: C=10, gamma= 0.1, kernel= 'rbf'</span></span>
<span id="cb131-786"><a href="#cb131-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-787"><a href="#cb131-787" aria-hidden="true" tabindex="-1"></a>svm_final_mod_bin<span class="op">=</span>svm.SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span> <span class="fl">0.1</span>, kernel<span class="op">=</span> <span class="st">'rbf'</span>)</span>
<span id="cb131-788"><a href="#cb131-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-789"><a href="#cb131-789" aria-hidden="true" tabindex="-1"></a>svm_final_mod_bin.fit(train_x_st, train_y_bin)</span>
<span id="cb131-790"><a href="#cb131-790" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>svm_final_mod_bin.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-791"><a href="#cb131-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-792"><a href="#cb131-792" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-793"><a href="#cb131-793" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-794"><a href="#cb131-794" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-795"><a href="#cb131-795" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-796"><a href="#cb131-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-797"><a href="#cb131-797" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-798"><a href="#cb131-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-799"><a href="#cb131-799" aria-hidden="true" tabindex="-1"></a><span class="fu">### K-Nearest Neighbors</span></span>
<span id="cb131-800"><a href="#cb131-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-803"><a href="#cb131-803" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb131-804"><a href="#cb131-804" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">3</span>)</span>
<span id="cb131-805"><a href="#cb131-805" aria-hidden="true" tabindex="-1"></a><span class="co">#3 Class, Outliers Kept: n-neighbors= 1</span></span>
<span id="cb131-806"><a href="#cb131-806" aria-hidden="true" tabindex="-1"></a>knn_final_mod<span class="op">=</span>KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb131-807"><a href="#cb131-807" aria-hidden="true" tabindex="-1"></a>knn_final_mod.fit(train_x_st, train_y)</span>
<span id="cb131-808"><a href="#cb131-808" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>knn_final_mod.predict(test_x) <span class="co">#make predictions on test set</span></span>
<span id="cb131-809"><a href="#cb131-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-810"><a href="#cb131-810" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-811"><a href="#cb131-811" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-812"><a href="#cb131-812" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-813"><a href="#cb131-813" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-814"><a href="#cb131-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-815"><a href="#cb131-815" aria-hidden="true" tabindex="-1"></a><span class="co">#Binary Outcome, Outliers Imputed: n-neighbors=3</span></span>
<span id="cb131-816"><a href="#cb131-816" aria-hidden="true" tabindex="-1"></a>knn_final_mod_bin<span class="op">=</span>KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb131-817"><a href="#cb131-817" aria-hidden="true" tabindex="-1"></a>knn_final_mod_bin.fit(train_x_st_no_out, train_y_bin)</span>
<span id="cb131-818"><a href="#cb131-818" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>knn_final_mod_bin.predict(test_x_no_out) <span class="co">#make predictions on test set</span></span>
<span id="cb131-819"><a href="#cb131-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-820"><a href="#cb131-820" aria-hidden="true" tabindex="-1"></a>f1_1 <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="st">'macro'</span>) <span class="co">#calculate macro f1</span></span>
<span id="cb131-821"><a href="#cb131-821" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_1)</span>
<span id="cb131-822"><a href="#cb131-822" aria-hidden="true" tabindex="-1"></a>f1_by_class <span class="op">=</span> f1_score(test_y_bin, y_pred, average<span class="op">=</span><span class="va">None</span>) <span class="co">#calculate by-class f1 scores</span></span>
<span id="cb131-823"><a href="#cb131-823" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_by_class)</span>
<span id="cb131-824"><a href="#cb131-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-825"><a href="#cb131-825" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb131-826"><a href="#cb131-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-827"><a href="#cb131-827" aria-hidden="true" tabindex="-1"></a><span class="fu"># Compare Models</span></span>
<span id="cb131-828"><a href="#cb131-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-829"><a href="#cb131-829" aria-hidden="true" tabindex="-1"></a>**Three-Class F1 Scores (Macro, By-Class):**</span>
<span id="cb131-830"><a href="#cb131-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-831"><a href="#cb131-831" aria-hidden="true" tabindex="-1"></a>Logistic Regression: 0.760 <span class="co">[</span><span class="ot">0.9402229, 0.58682635, 0.75409836</span><span class="co">]</span></span>
<span id="cb131-832"><a href="#cb131-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-833"><a href="#cb131-833" aria-hidden="true" tabindex="-1"></a>Boosting: 0.924 <span class="co">[</span><span class="ot">0.97341513, 0.8452381, 0.95384615</span><span class="co">]</span></span>
<span id="cb131-834"><a href="#cb131-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-835"><a href="#cb131-835" aria-hidden="true" tabindex="-1"></a>SVM: 0.841 <span class="co">[</span><span class="ot">0.95634518, 0.78212291, 0.78571429</span><span class="co">]</span></span>
<span id="cb131-836"><a href="#cb131-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-837"><a href="#cb131-837" aria-hidden="true" tabindex="-1"></a>KNN: 0.792 <span class="co">[</span><span class="ot">0.94512195, 0.65895954, 0.77310924</span><span class="co">]</span></span>
<span id="cb131-838"><a href="#cb131-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-839"><a href="#cb131-839" aria-hidden="true" tabindex="-1"></a>**Binary Outcome F1 Scores (Macro, By-Class):**</span>
<span id="cb131-840"><a href="#cb131-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-841"><a href="#cb131-841" aria-hidden="true" tabindex="-1"></a>Logistic Regression: 0.869 <span class="co">[</span><span class="ot">0.94010152 0.79725086</span><span class="co">]</span></span>
<span id="cb131-842"><a href="#cb131-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-843"><a href="#cb131-843" aria-hidden="true" tabindex="-1"></a>Boosting: 0.947 <span class="co">[</span><span class="ot">0.97546012, 0.91946309</span><span class="co">]</span></span>
<span id="cb131-844"><a href="#cb131-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-845"><a href="#cb131-845" aria-hidden="true" tabindex="-1"></a>SVM: 0.912 <span class="co">[</span><span class="ot">0.9591002, 0.86577181</span><span class="co">]</span></span>
<span id="cb131-846"><a href="#cb131-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-847"><a href="#cb131-847" aria-hidden="true" tabindex="-1"></a>KNN: 0.851 <span class="co">[</span><span class="ot">0.93612774 0.76642336</span><span class="co">]</span></span>
<span id="cb131-848"><a href="#cb131-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-849"><a href="#cb131-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-850"><a href="#cb131-850" aria-hidden="true" tabindex="-1"></a>The best performing model for both a three-class outcome and a binary outcome was the model created with XGBoost. These models actually performed slightly better when trained on the full training set and tested on the held-out test set than they did during cross validation. This is likely because the final model was trained on a larger dataset. Boosting slowly learns through a sequential algorithm where trees are fit on residuals from the previous tree. Because we are fitting many trees, this algorithm is less prone to overfitting. While XGBoost reduces bias and can produce very good predictions, this model is less interpretable than other models such as logistic regression.</span>
<span id="cb131-851"><a href="#cb131-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-852"><a href="#cb131-852" aria-hidden="true" tabindex="-1"></a>Logistic regression is the most biased model used in this analysis. Because this model has low flexibility it could not learn as much from the training data as models like boosting, SVM and KNN can. However, this is likely the most interpretable model from this analysis. While interpretable, the logistic regression model does not perform well enough to be used, especially given performance on the "suspect" and "pathological" cases.</span>
<span id="cb131-853"><a href="#cb131-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-854"><a href="#cb131-854" aria-hidden="true" tabindex="-1"></a>After boosting, the best performing model was support vector machines (SVM). SVM does a better job classifying "suspect" and "pathological" cases than KNN and logisitic regression, especially on a binary outcome variable. One advantage of SVM is we can impose a softer margin by increasing C (increasing bias), which likely helped SVM learn the nuances of classification of these categories without increasing the variance. SVM also allows us to model highly non-linear relationships (this is likely the case for out data given logistic regression did not perform well). In our case, the optimal kernel was a radial kernel which can perform well in a dataset of higher dimensions.</span>
<span id="cb131-855"><a href="#cb131-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-856"><a href="#cb131-856" aria-hidden="true" tabindex="-1"></a>Finally I tested K-Nearest Neighbors to see if a low bias, high variance model could perform well given our data did not seem to follow a linear relationship. This was not the case, KNN performed similarly to logistic regression, suggesting a model that has a balance between bias and variance would work better with our data. KNN is also not very interpretable. KNN had the lowest score of all the models on the test set for the binary outcome class (and also a low score for the three class outcome) thus, it was likely overfitting to the training data (especially given the optimized k for the 3 class outcome was 1).</span>
<span id="cb131-857"><a href="#cb131-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-858"><a href="#cb131-858" aria-hidden="true" tabindex="-1"></a><span class="fu"># Ethical Implications</span></span>
<span id="cb131-859"><a href="#cb131-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-860"><a href="#cb131-860" aria-hidden="true" tabindex="-1"></a>While I was hoping to land on an interpretable model so one could easily interpret what may be flagging a case as "suspect" or "pathological", in the case of CTGs, a better performing model is more important than an interpretable model.</span>
<span id="cb131-861"><a href="#cb131-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-862"><a href="#cb131-862" aria-hidden="true" tabindex="-1"></a>While boosted models are not very interpretable, the performance is the best for both a 3-class outcome variable and a binary outcome variable.</span>
<span id="cb131-863"><a href="#cb131-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-864"><a href="#cb131-864" aria-hidden="true" tabindex="-1"></a>In an outpatient setting, where there is more time to take a closer look at the CTGs, I might suggest using the boosted model with a binary outcome (macro f1= 0.947, f1 for class "normal"= 0.975, f1 for class "suspect/pathological"= 0.919"). This is because the "suspect" case is still difficult to detect in the three-class outcome, so the better f1 score for the combined outcome might be better for flagging suspect cases in addition to pathological cases. In an outpatient setting, the medical professional can then look closer at the flagged cases, interpret why they are being flagged and then class them as "suspect" or "pathological". For a labor setting, time is more critical, and immediate flagging of pathological cases is more critical. In a labor setting, I would suggest using the boosted 3-class outcome since it performs better on the pathological cases (and suspect cases are not necessarily in need of immediate attention) (macro f1=0.924, f1 for "normal"= 0.973, f1 for "suspect"= 0.845, and f1 for "pathological"= 0.954).</span>
<span id="cb131-865"><a href="#cb131-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-866"><a href="#cb131-866" aria-hidden="true" tabindex="-1"></a>Because in general, f1 scores for suspect and pathological classes are much lower than for normal, I am not sure I would ever feel comfortable with this model being deployed without a human medical professional also analyzing the CTG and making a decision for themselves. Finally, before being deployed, such a model should be trained on a much larger data set than was done in this analysis (to avoid overfitting).</span>
<span id="cb131-867"><a href="#cb131-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-868"><a href="#cb131-868" aria-hidden="true" tabindex="-1"></a>While my original aim was to come up with a high-performing interpretable model, given the low f1 score for suspect/pathological classes, I would consider training a neural network/deep learning model in the future if such a model is able to achieve better performance. However, even if a much higher performing, neural network or other machine learning model is developed, it should not be deployed without people trained to read CTGs analyzing the document for themselves given the low interpretablilty of such an algorithm.</span>
<span id="cb131-869"><a href="#cb131-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-870"><a href="#cb131-870" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span>
<span id="cb131-871"><a href="#cb131-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-872"><a href="#cb131-872" aria-hidden="true" tabindex="-1"></a>Dataset: Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318 (<span class="co">[</span><span class="ot">https://onlinelibrary.wiley.com/doi/10.1002/1520-6661(200009/10)9:5%3C311</span><span class="co">]</span>(https://onlinelibrary.wiley.com/doi/10.1002/1520-6661(200009/10)9:5%3C311){.uri}::AID-MFM12%3E3.0.CO;2-9)</span>
<span id="cb131-873"><a href="#cb131-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-874"><a href="#cb131-874" aria-hidden="true" tabindex="-1"></a>Cariotocography. (Accessed May 24, 2023). Wikipedia. <span class="ot">&lt;https://en.wikipedia.org/wiki/Cardiotocography&gt;</span>. Fetal Health Classification. (Accessed May 24, 2023).</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>